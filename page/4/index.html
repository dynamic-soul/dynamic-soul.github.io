<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-CN">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2"/>
<meta name="theme-color" content="#222">






  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />






















<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=6.0.6" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.0.6">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.0.6">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.0.6">


  <link rel="mask-icon" href="/images/logo.svg?v=6.0.6" color="#222">









<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '6.0.6',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="我希望时间没有流走，世界还停在过去，昏黄的光还照在旧日的路上，我刚刚走过，恰与你们相识。">
<meta property="og:type" content="website">
<meta property="og:title" content="Dynamic-Soul">
<meta property="og:url" content="http://yoursite.com/page/4/index.html">
<meta property="og:site_name" content="Dynamic-Soul">
<meta property="og:description" content="我希望时间没有流走，世界还停在过去，昏黄的光还照在旧日的路上，我刚刚走过，恰与你们相识。">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Dynamic-Soul">
<meta name="twitter:description" content="我希望时间没有流走，世界还停在过去，昏黄的光还照在旧日的路上，我刚刚走过，恰与你们相识。">






  <link rel="canonical" href="http://yoursite.com/page/4/"/>



<script type="text/javascript" id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Dynamic-Soul</title>
  









  <noscript>
  <style type="text/css">
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion {
      .logo-line-before i { left: initial; }
      .logo-line-after i { right: initial; }
    }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <a href="https://github.com/dynamic-soul"><img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_gray_6d6d6d.png" alt="Fork me on GitHub"></a>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"> 

<div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Dynamic-Soul</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        
          
  <li class="menu-item menu-item-home">
    <a href="/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-home"></i> <br />首页</a>
</li>

      
        
        
          
  <li class="menu-item menu-item-about">
    <a href="/about/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-user"></i> <br />关于</a>
</li>

      
        
        
          
  <li class="menu-item menu-item-tags">
    <a href="/tags/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />标签</a>
</li>

      
        
        
          
  <li class="menu-item menu-item-categories">
    <a href="/categories/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-th"></i> <br />分类</a>
</li>

      
        
        
          
  <li class="menu-item menu-item-archives">
    <a href="/archives/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />归档</a>
</li>

      

      
    </ul>
  

  

  
</nav>


  



 </div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/12/2018051221/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mr.Q">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Dynamic-Soul">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/12/2018051221/" itemprop="url">糗事百科实例</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-12T21:33:51+08:00">2018-05-12</time>
            

            
            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/爬虫/" itemprop="url" rel="index"><span itemprop="name">爬虫</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="糗事百科实例："><a href="#糗事百科实例：" class="headerlink" title="糗事百科实例："></a>糗事百科实例：</h1><p>爬取糗事百科段子，假设页面的URL是 <a href="http://www.qiushibaike.com/8hr/page/1" target="_blank" rel="noopener">http://www.qiushibaike.com/8hr/page/1</a></p>
<h2 id="要求："><a href="#要求：" class="headerlink" title="要求："></a>要求：</h2><ol>
<li><p>使用requests获取页面信息，用XPath / re 做数据提取</p>
</li>
<li><p>获取每个帖子里的用户头像链接、用户姓名、段子内容、点赞次数和评论次数</p>
</li>
<li><p>保存到 json 文件内</p>
</li>
</ol>
<h2 id="参考代码"><a href="#参考代码" class="headerlink" title="参考代码"></a>参考代码</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#qiushibaike.py</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#import urllib</span></span><br><span class="line"><span class="comment">#import re</span></span><br><span class="line"><span class="comment">#import chardet</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line">page = <span class="number">1</span></span><br><span class="line">url = <span class="string">'http://www.qiushibaike.com/8hr/page/'</span> + str(page) </span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.36'</span>,</span><br><span class="line">    <span class="string">'Accept-Language'</span>: <span class="string">'zh-CN,zh;q=0.8'</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    response = requests.get(url, headers=headers)</span><br><span class="line">    resHtml = response.text</span><br><span class="line"></span><br><span class="line">    html = etree.HTML(resHtml)</span><br><span class="line">    result = html.xpath(<span class="string">'//div[contains(@id,"qiushi_tag")]'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> site <span class="keyword">in</span> result:</span><br><span class="line">        item = &#123;&#125;</span><br><span class="line"></span><br><span class="line">        imgUrl = site.xpath(<span class="string">'./div/a/img/@src'</span>)[<span class="number">0</span>].encode(<span class="string">'utf-8'</span>)</span><br><span class="line">        username = site.xpath(<span class="string">'./div/a/@title'</span>)[<span class="number">0</span>].encode(<span class="string">'utf-8'</span>)</span><br><span class="line">        <span class="comment">#username = site.xpath('.//h2')[0].text</span></span><br><span class="line">        content = site.xpath(<span class="string">'.//div[@class="content"]/span'</span>)[<span class="number">0</span>].text.strip().encode(<span class="string">'utf-8'</span>)</span><br><span class="line">        <span class="comment"># 投票次数</span></span><br><span class="line">        vote = site.xpath(<span class="string">'.//i'</span>)[<span class="number">0</span>].text</span><br><span class="line">        <span class="comment">#print site.xpath('.//*[@class="number"]')[0].text</span></span><br><span class="line">        <span class="comment"># 评论信息</span></span><br><span class="line">        comments = site.xpath(<span class="string">'.//i'</span>)[<span class="number">1</span>].text</span><br><span class="line"></span><br><span class="line">        <span class="keyword">print</span> imgUrl, username, content, vote, comments</span><br><span class="line"></span><br><span class="line"><span class="keyword">except</span> Exception, e:</span><br><span class="line">    <span class="keyword">print</span> e</span><br></pre></td></tr></table></figure>
<h2 id="演示效果"><a href="#演示效果" class="headerlink" title="演示效果"></a>演示效果</h2><img src="/2018/05/12/2018051221/1.jpg">

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/11/2018051121/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mr.Q">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Dynamic-Soul">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/11/2018051121/" itemprop="url">JSON模块与JsonPath</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-11T20:07:31+08:00">2018-05-11</time>
            

            
            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/爬虫/" itemprop="url" rel="index"><span itemprop="name">爬虫</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="数据提取之JSON与JsonPATH"><a href="#数据提取之JSON与JsonPATH" class="headerlink" title="数据提取之JSON与JsonPATH"></a>数据提取之JSON与JsonPATH</h1><p>JSON(JavaScript Object Notation) 是一种轻量级的数据交换格式，它使得人们很容易的进行阅读和编写。同时也方便了机器进行解析和生成。适用于进行数据交互的场景，比如网站前台与后台之间的数据交互。</p>
<p>JSON和XML的比较可谓不相上下。</p>
<p>Python 2.7中自带了JSON模块，直接import json就可以使用了。</p>
<p>官方文档：<a href="http://docs.python.org/library/json.html" target="_blank" rel="noopener">http://docs.python.org/library/json.html</a></p>
<p>Json在线解析网站：<a href="http://www.json.cn/#" target="_blank" rel="noopener">http://www.json.cn/#</a></p>
<p>#JSON</p>
<p>json简单说就是javascript中的对象和数组，所以这两种结构就是对象和数组两种结构，通过这两种结构可以表示各种复杂的结构</p>
<pre><code>1. 对象：对象在js中表示为{ }括起来的内容，数据结构为 { key：value, key：value, ... }的键值对的结构，在面向对象的语言中，key为对象的属性，value为对应的属性值，所以很容易理解，取值方法为 对象.key 获取属性值，这个属性值的类型可以是数字、字符串、数组、对象这几种。

2. 数组：数组在js中是中括号[ ]括起来的内容，数据结构为 [&quot;Python&quot;, &quot;javascript&quot;, &quot;C++&quot;, ...]，取值方式和所有语言中一样，使用索引获取，字段值的类型可以是 数字、字符串、数组、对象几种。
</code></pre><h2 id="import-json"><a href="#import-json" class="headerlink" title="import json"></a>import json</h2><p>json模块提供了四个功能：dumps、dump、loads、load，用于字符串 和 python数据类型间进行转换。</p>
<h3 id="1-json-loads"><a href="#1-json-loads" class="headerlink" title="1. json.loads()"></a>1. json.loads()</h3><p>把Json格式字符串解码转换成Python对象 从json到python的类型转化对照如下：</p>
<img src="/2018/05/11/2018051121/1.jpg">
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># json_loads.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">strList = <span class="string">'[1, 2, 3, 4]'</span></span><br><span class="line"></span><br><span class="line">strDict = <span class="string">'&#123;"city": "北京", "name": "大猫"&#125;'</span></span><br><span class="line"></span><br><span class="line">json.loads(strList) </span><br><span class="line"><span class="comment"># [1, 2, 3, 4]</span></span><br><span class="line"></span><br><span class="line">json.loads(strDict) <span class="comment"># json数据自动按Unicode存储</span></span><br><span class="line"><span class="comment"># &#123;u'city': u'\u5317\u4eac', u'name': u'\u5927\u732b'&#125;</span></span><br></pre></td></tr></table></figure>
<h3 id="2-json-dumps"><a href="#2-json-dumps" class="headerlink" title="2. json.dumps()"></a>2. json.dumps()</h3><p>实现python类型转化为json字符串，返回一个str对象 把一个Python对象编码转换成Json字符串</p>
<p>从python原始类型向json类型的转化对照如下：</p>
<img src="/2018/05/11/2018051121/2.jpg">
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># json_dumps.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> chardet</span><br><span class="line"></span><br><span class="line">listStr = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]</span><br><span class="line">tupleStr = (<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">dictStr = &#123;<span class="string">"city"</span>: <span class="string">"北京"</span>, <span class="string">"name"</span>: <span class="string">"大猫"</span>&#125;</span><br><span class="line"></span><br><span class="line">json.dumps(listStr)</span><br><span class="line"><span class="comment"># '[1, 2, 3, 4]'</span></span><br><span class="line">json.dumps(tupleStr)</span><br><span class="line"><span class="comment"># '[1, 2, 3, 4]'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 注意：json.dumps() 序列化时默认使用的ascii编码</span></span><br><span class="line"><span class="comment"># 添加参数 ensure_ascii=False 禁用ascii编码，按utf-8编码</span></span><br><span class="line"><span class="comment"># chardet.detect()返回字典, 其中confidence是检测精确度</span></span><br><span class="line"></span><br><span class="line">json.dumps(dictStr) </span><br><span class="line"><span class="comment"># '&#123;"city": "\\u5317\\u4eac", "name": "\\u5927\\u5218"&#125;'</span></span><br><span class="line"></span><br><span class="line">chardet.detect(json.dumps(dictStr))</span><br><span class="line"><span class="comment"># &#123;'confidence': 1.0, 'encoding': 'ascii'&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> json.dumps(dictStr, ensure_ascii=<span class="keyword">False</span>) </span><br><span class="line"><span class="comment"># &#123;"city": "北京", "name": "大刘"&#125;</span></span><br><span class="line"></span><br><span class="line">chardet.detect(json.dumps(dictStr, ensure_ascii=<span class="keyword">False</span>))</span><br><span class="line"><span class="comment"># &#123;'confidence': 0.99, 'encoding': 'utf-8'&#125;</span></span><br></pre></td></tr></table></figure>
<p><em>chardet是一个非常优秀的编码识别模块，可通过pip安装</em></p>
<h3 id="3-json-dump"><a href="#3-json-dump" class="headerlink" title="3. json.dump()"></a>3. json.dump()</h3><p>将Python内置类型序列化为json对象后写入文件<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># json_dump.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">listStr = [&#123;<span class="string">"city"</span>: <span class="string">"北京"</span>&#125;, &#123;<span class="string">"name"</span>: <span class="string">"大刘"</span>&#125;]</span><br><span class="line">json.dump(listStr, open(<span class="string">"listStr.json"</span>,<span class="string">"w"</span>), ensure_ascii=<span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line">dictStr = &#123;<span class="string">"city"</span>: <span class="string">"北京"</span>, <span class="string">"name"</span>: <span class="string">"大刘"</span>&#125;</span><br><span class="line">json.dump(dictStr, open(<span class="string">"dictStr.json"</span>,<span class="string">"w"</span>), ensure_ascii=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure></p>
<h3 id="4-json-load"><a href="#4-json-load" class="headerlink" title="4. json.load()"></a>4. json.load()</h3><p>读取文件中json形式的字符串元素 转化成python类型<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># json_load.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line">strList = json.load(open(<span class="string">"listStr.json"</span>))</span><br><span class="line"><span class="keyword">print</span> strList</span><br><span class="line"></span><br><span class="line"><span class="comment"># [&#123;u'city': u'\u5317\u4eac'&#125;, &#123;u'name': u'\u5927\u5218'&#125;]</span></span><br><span class="line"></span><br><span class="line">strDict = json.load(open(<span class="string">"dictStr.json"</span>))</span><br><span class="line"><span class="keyword">print</span> strDict</span><br><span class="line"><span class="comment"># &#123;u'city': u'\u5317\u4eac', u'name': u'\u5927\u5218'&#125;</span></span><br></pre></td></tr></table></figure></p>
<h1 id="JsonPath"><a href="#JsonPath" class="headerlink" title="JsonPath"></a>JsonPath</h1><p>JsonPath 是一种信息抽取类库，是从JSON文档中抽取指定信息的工具，提供多种语言实现版本，包括：Javascript, Python， PHP 和 Java。</p>
<p>JsonPath 对于 JSON 来说，相当于 XPATH 对于 XML。</p>
<pre><code>下载地址：https://pypi.python.org/pypi/jsonpath

安装方法：点击Download URL链接下载jsonpath，解压之后执行python setup.py install

官方文档：http://goessner.net/articles/JsonPath
</code></pre><h2 id="JsonPath与XPath语法对比："><a href="#JsonPath与XPath语法对比：" class="headerlink" title="JsonPath与XPath语法对比："></a>JsonPath与XPath语法对比：</h2><p>Json结构清晰，可读性高，复杂度低，非常容易匹配，下表中对应了XPath的用法。<br>|XPath|     JSONPath|     描述|<br>|—–|—–|—–|<br>|/ |    $ |    根节点|<br>|.|     @ |    现行节点|<br>|/ |    .or[] |    取子节点|<br>|..     |n/a |    取父节点，Jsonpath未支持|<br>|// |    ..     就是不管位置，选择所有符合条件的条件|<br>|<em> |    </em> |    匹配所有元素节点|<br>|@|     n/a |    根据属性访问，Json不支持，因为Json是个Key-value递归结构，不需要。|<br>|[] |    [] |    迭代器标示（可以在里边做简单的迭代操作，如数组下标，根据内容选值等）|<br>| |     |[,] |    支持迭代器中做多选。|<br>|[] |    ?() |    支持过滤操作.|<br>|n/a|     ()     |支持表达式计算|<br>|() |    n/a|     分组，JsonPath不支持|</p>
<h2 id="示例："><a href="#示例：" class="headerlink" title="示例："></a>示例：</h2><p>我们以拉勾网城市JSON文件 <a href="http://www.lagou.com/lbs/getAllCitySearchLabels.json" target="_blank" rel="noopener">http://www.lagou.com/lbs/getAllCitySearchLabels.json</a> 为例，获取所有城市。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># jsonpath_lagou.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line"><span class="keyword">import</span> jsonpath</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> chardet</span><br><span class="line"></span><br><span class="line">url = <span class="string">'http://www.lagou.com/lbs/getAllCitySearchLabels.json'</span></span><br><span class="line">request =urllib2.Request(url)</span><br><span class="line">response = urllib2.urlopen(request)</span><br><span class="line">html = response.read()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 把json格式字符串转换成python对象</span></span><br><span class="line">jsonobj = json.loads(html)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 从根节点开始，匹配name节点</span></span><br><span class="line">citylist = jsonpath.jsonpath(jsonobj,<span class="string">'$..name'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> citylist</span><br><span class="line"><span class="keyword">print</span> type(citylist)</span><br><span class="line">fp = open(<span class="string">'city.json'</span>,<span class="string">'w'</span>)</span><br><span class="line"></span><br><span class="line">content = json.dumps(citylist, ensure_ascii=<span class="keyword">False</span>)</span><br><span class="line"><span class="keyword">print</span> content</span><br><span class="line"></span><br><span class="line">fp.write(content.encode(<span class="string">'utf-8'</span>))</span><br><span class="line">fp.close()</span><br></pre></td></tr></table></figure>
<h2 id="注意事项："><a href="#注意事项：" class="headerlink" title="注意事项："></a>注意事项：</h2><p>json.loads() 是把 Json格式字符串解码转换成Python对象，如果在json.loads的时候出错，要注意被解码的Json字符的编码。</p>
<p>如果传入的字符串的编码不是UTF-8的话，需要指定字符编码的参数 encoding<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataDict = json.loads(jsonStrGBK);</span><br></pre></td></tr></table></figure></p>
<ul>
<li><p>dataJsonStr是JSON字符串，假设其编码本身是非UTF-8的话而是GBK 的，那么上述代码会导致出错，改为对应的:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataDict = json.loads(jsonStrGBK, encoding=<span class="string">"GBK"</span>);</span><br></pre></td></tr></table></figure>
</li>
<li><p>如果 dataJsonStr通过encoding指定了合适的编码，但是其中又包含了其他编码的字符，则需要先去将dataJsonStr转换为Unicode，然后再指定编码格式调用json.loads() </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataJsonStrUni = dataJsonStr.decode(<span class="string">"GB2312"</span>); dataDict = json.loads(dataJsonStrUni, encoding=<span class="string">"GB2312"</span>);</span><br></pre></td></tr></table></figure>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">##字符串编码转换</span></span><br><span class="line"></span><br><span class="line">这是中国程序员最苦逼的地方，什么乱码之类的几乎都是由汉字引起的。</span><br><span class="line">其实编码问题很好搞定，只要记住一点：</span><br><span class="line"></span><br><span class="line"><span class="comment">####任何平台的任何编码 都能和 Unicode 互相转换</span></span><br><span class="line"></span><br><span class="line">UTF<span class="number">-8</span> 与 GBK 互相转换，那就先把UTF<span class="number">-8</span>转换成Unicode，再从Unicode转换成GBK，反之同理。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">``` python </span><br><span class="line"><span class="comment"># 这是一个 UTF-8 编码的字符串</span></span><br><span class="line">utf8Str = <span class="string">"你好地球"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 将 UTF-8 编码的字符串 转换成 Unicode 编码</span></span><br><span class="line">unicodeStr = utf8Str.decode(<span class="string">"UTF-8"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 再将 Unicode 编码格式字符串 转换成 GBK 编码</span></span><br><span class="line">gbkData = unicodeStr.encode(<span class="string">"GBK"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 再将 GBK 编码格式字符串 转化成 Unicode</span></span><br><span class="line">unicodeStr = gbkData.decode(<span class="string">"gbk"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 再将 Unicode 编码格式字符串转换成 UTF-8</span></span><br><span class="line">utf8Str = unicodeStr.encode(<span class="string">"UTF-8"</span>)</span><br></pre></td></tr></table></figure>
<p>decode的作用是将其他编码的字符串转换成 Unicode 编码</p>
<p>encode的作用是将 Unicode 编码转换成其他编码的字符串</p>
<p>一句话：UTF-8是对Unicode字符集进行编码的一种编码方式</p>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/11/2018051120/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mr.Q">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Dynamic-Soul">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/11/2018051120/" itemprop="url">案例：使用BeautifuSoup4的爬虫</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-11T20:00:17+08:00">2018-05-11</time>
            

            
            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/爬虫/" itemprop="url" rel="index"><span itemprop="name">爬虫</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="案例：使用BeautifuSoup4的爬虫"><a href="#案例：使用BeautifuSoup4的爬虫" class="headerlink" title="案例：使用BeautifuSoup4的爬虫"></a>案例：使用BeautifuSoup4的爬虫</h1><p>我们以腾讯社招页面来做演示：<a href="http://hr.tencent.com/position.php?&amp;start=10#a" target="_blank" rel="noopener">http://hr.tencent.com/position.php?&amp;start=10#a</a></p>
<img src="/2018/05/11/2018051120/1.jpg">
<p>使用BeautifuSoup4解析器，将招聘网页上的职位名称、职位类别、招聘人数、工作地点、发布时间，以及每个职位详情的点击链接存储出来。</p>
<img src="/2018/05/11/2018051120/2.jpg">
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># bs4_tencent.py</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line"><span class="keyword">import</span> urllib</span><br><span class="line"><span class="keyword">import</span> json    <span class="comment"># 使用了json格式存储</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tencent</span><span class="params">()</span>:</span></span><br><span class="line">    url = <span class="string">'http://hr.tencent.com/'</span></span><br><span class="line">    request = urllib2.Request(url + <span class="string">'position.php?&amp;start=10#a'</span>)</span><br><span class="line">    response =urllib2.urlopen(request)</span><br><span class="line">    resHtml = response.read()</span><br><span class="line"></span><br><span class="line">    output =open(<span class="string">'tencent.json'</span>,<span class="string">'w'</span>)</span><br><span class="line"></span><br><span class="line">    html = BeautifulSoup(resHtml,<span class="string">'lxml'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建CSS选择器</span></span><br><span class="line">    result = html.select(<span class="string">'tr[class="even"]'</span>)</span><br><span class="line">    result2 = html.select(<span class="string">'tr[class="odd"]'</span>)</span><br><span class="line">    result += result2</span><br><span class="line"></span><br><span class="line">    items = []</span><br><span class="line">    <span class="keyword">for</span> site <span class="keyword">in</span> result:</span><br><span class="line">        item = &#123;&#125;</span><br><span class="line"></span><br><span class="line">        name = site.select(<span class="string">'td a'</span>)[<span class="number">0</span>].get_text()</span><br><span class="line">        detailLink = site.select(<span class="string">'td a'</span>)[<span class="number">0</span>].attrs[<span class="string">'href'</span>]</span><br><span class="line">        catalog = site.select(<span class="string">'td'</span>)[<span class="number">1</span>].get_text()</span><br><span class="line">        recruitNumber = site.select(<span class="string">'td'</span>)[<span class="number">2</span>].get_text()</span><br><span class="line">        workLocation = site.select(<span class="string">'td'</span>)[<span class="number">3</span>].get_text()</span><br><span class="line">        publishTime = site.select(<span class="string">'td'</span>)[<span class="number">4</span>].get_text()</span><br><span class="line"></span><br><span class="line">        item[<span class="string">'name'</span>] = name</span><br><span class="line">        item[<span class="string">'detailLink'</span>] = url + detailLink</span><br><span class="line">        item[<span class="string">'catalog'</span>] = catalog</span><br><span class="line">        item[<span class="string">'recruitNumber'</span>] = recruitNumber</span><br><span class="line">        item[<span class="string">'publishTime'</span>] = publishTime</span><br><span class="line"></span><br><span class="line">        items.append(item)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 禁用ascii编码，按utf-8编码</span></span><br><span class="line">    line = json.dumps(items,ensure_ascii=<span class="keyword">False</span>)</span><br><span class="line"></span><br><span class="line">    output.write(line.encode(<span class="string">'utf-8'</span>))</span><br><span class="line">    output.close()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">   tencent()</span><br></pre></td></tr></table></figure>
          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/10/2018051020/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mr.Q">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Dynamic-Soul">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/10/2018051020/" itemprop="url">BeautifulSoup4解析器</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-10T19:53:34+08:00">2018-05-10</time>
            

            
            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/爬虫/" itemprop="url" rel="index"><span itemprop="name">爬虫</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="CSS-选择器：BeautifulSoup4"><a href="#CSS-选择器：BeautifulSoup4" class="headerlink" title="CSS 选择器：BeautifulSoup4"></a>CSS 选择器：BeautifulSoup4</h1><p>和 lxml 一样，Beautiful Soup 也是一个HTML/XML的解析器，主要的功能也是如何解析和提取 HTML/XML 数据。</p>
<pre><code>lxml 只会局部遍历，而Beautiful Soup 是基于HTML DOM的，会载入整个文档，解析整个DOM树，因此时间和内存开销都会大很多，所以性能要低于lxml。

BeautifulSoup 用来解析 HTML 比较简单，API非常人性化，支持CSS选择器、Python标准库中的HTML解析器，也支持 lxml 的 XML解析器。

Beautiful Soup 3 目前已经停止开发，推荐现在的项目使用Beautiful Soup 4。使用 pip 安装即可：pip install beautifulsoup4

官方文档：http://beautifulsoup.readthedocs.io/zh_CN/v4.4.0
</code></pre><table>
<thead>
<tr>
<th>抓取工具</th>
<th>速度</th>
<th>使用难度</th>
<th>安装难度</th>
</tr>
</thead>
<tbody>
<tr>
<td>正则</td>
<td>最快</td>
<td>困难</td>
<td>无（内置）</td>
</tr>
<tr>
<td>BeautifulSoup</td>
<td>慢</td>
<td>最简单</td>
<td>简单</td>
</tr>
<tr>
<td>lxml</td>
<td>快</td>
<td>简单</td>
<td>一般</td>
</tr>
</tbody>
</table>
<h2 id="实例："><a href="#实例：" class="headerlink" title="实例："></a>实例：</h2><p>首先必须要导入bs4库<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># beautifulsoup4_test.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">html = <span class="string">"""</span></span><br><span class="line"><span class="string">&lt;html&gt;&lt;head&gt;&lt;title&gt;The Dormouse's story&lt;/title&gt;&lt;/head&gt;</span></span><br><span class="line"><span class="string">&lt;body&gt;</span></span><br><span class="line"><span class="string">&lt;p class="title" name="dromouse"&gt;&lt;b&gt;The Dormouse's story&lt;/b&gt;&lt;/p&gt;</span></span><br><span class="line"><span class="string">&lt;p class="story"&gt;Once upon a time there were three little sisters; and their names were</span></span><br><span class="line"><span class="string">&lt;a href="http://example.com/elsie" class="sister" id="link1"&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;,</span></span><br><span class="line"><span class="string">&lt;a href="http://example.com/lacie" class="sister" id="link2"&gt;Lacie&lt;/a&gt; and</span></span><br><span class="line"><span class="string">&lt;a href="http://example.com/tillie" class="sister" id="link3"&gt;Tillie&lt;/a&gt;;</span></span><br><span class="line"><span class="string">and they lived at the bottom of a well.&lt;/p&gt;</span></span><br><span class="line"><span class="string">&lt;p class="story"&gt;...&lt;/p&gt;</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#创建 Beautiful Soup 对象</span></span><br><span class="line">soup = BeautifulSoup(html)</span><br><span class="line"></span><br><span class="line"><span class="comment">#打开本地 HTML 文件的方式来创建对象</span></span><br><span class="line"><span class="comment">#soup = BeautifulSoup(open('index.html'))</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#格式化输出 soup 对象的内容</span></span><br><span class="line"><span class="keyword">print</span> soup.prettify()</span><br></pre></td></tr></table></figure></p>
<p>运行结果<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">&lt;html&gt;</span><br><span class="line"> &lt;head&gt;</span><br><span class="line">  &lt;title&gt;</span><br><span class="line">   The Dormouse<span class="string">'s story</span></span><br><span class="line"><span class="string">  &lt;/title&gt;</span></span><br><span class="line"><span class="string"> &lt;/head&gt;</span></span><br><span class="line"><span class="string"> &lt;body&gt;</span></span><br><span class="line"><span class="string">  &lt;p class="title" name="dromouse"&gt;</span></span><br><span class="line"><span class="string">   &lt;b&gt;</span></span><br><span class="line"><span class="string">    The Dormouse'</span>s story</span><br><span class="line">   &lt;/b&gt;</span><br><span class="line">  &lt;/p&gt;</span><br><span class="line">  &lt;p class="story"&gt;</span><br><span class="line">   Once upon a time there were three little sisters; <span class="keyword">and</span> their names were</span><br><span class="line">   &lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;</span><br><span class="line">    &lt;!-- Elsie --&gt;</span><br><span class="line">   &lt;/a&gt;</span><br><span class="line">   ,</span><br><span class="line">   &lt;a class="sister" href="http://example.com/lacie" id="link2"&gt;</span><br><span class="line">    Lacie</span><br><span class="line">   &lt;/a&gt;</span><br><span class="line">   <span class="keyword">and</span></span><br><span class="line">   &lt;a class="sister" href="http://example.com/tillie" id="link3"&gt;</span><br><span class="line">    Tillie</span><br><span class="line">   &lt;/a&gt;</span><br><span class="line">   ;</span><br><span class="line"><span class="keyword">and</span> they lived at the bottom of a well.</span><br><span class="line">  &lt;/p&gt;</span><br><span class="line">  &lt;p class="story"&gt;</span><br><span class="line">   ...</span><br><span class="line">  &lt;/p&gt;</span><br><span class="line"> &lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br></pre></td></tr></table></figure></p>
<pre><code>- 如果我们在 IPython2 下执行，会看到这样一段警告：
</code></pre><img src="/2018/05/10/2018051020/1.jpg">
<pre><code>- 意思是，如果我们没有显式地指定解析器，所以默认使用这个系统的最佳可用HTML解析器(“lxml”)。如果你在另一个系统中运行这段代码，或者在不同的虚拟环境中，使用不同的解析器造成行为不同。
- 但是我们可以通过soup = BeautifulSoup(html,“lxml”)方式指定lxml解析器。
</code></pre><h2 id="四大对象种类"><a href="#四大对象种类" class="headerlink" title="四大对象种类"></a>四大对象种类</h2><p>Beautiful Soup将复杂HTML文档转换成一个复杂的树形结构,每个节点都是Python对象,所有对象可以归纳为4种:</p>
<ul>
<li>Tag</li>
<li>NavigableString</li>
<li>BeautifulSoup</li>
<li>Comment<br><strong>1. Tag</strong><br>Tag 通俗点讲就是 HTML 中的一个个标签，例如：<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;head&gt;&lt;title&gt;The Dormouse<span class="string">'s story&lt;/title&gt;&lt;/head&gt;</span></span><br><span class="line"><span class="string">&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;</span></span><br><span class="line">&lt;p class="title" name="dromouse"&gt;&lt;b&gt;The Dormouse's story&lt;/b&gt;&lt;/p&gt;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>上面的 title head a p等等 HTML 标签加上里面包括的内容就是 Tag，那么试着使用 Beautiful Soup 来获取 Tags:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line">html = <span class="string">"""</span></span><br><span class="line"><span class="string">&lt;html&gt;&lt;head&gt;&lt;title&gt;The Dormouse's story&lt;/title&gt;&lt;/head&gt;</span></span><br><span class="line"><span class="string">&lt;body&gt;</span></span><br><span class="line"><span class="string">&lt;p class="title" name="dromouse"&gt;&lt;b&gt;The Dormouse's story&lt;/b&gt;&lt;/p&gt;</span></span><br><span class="line"><span class="string">&lt;p class="story"&gt;Once upon a time there were three little sisters; and their names were</span></span><br><span class="line"><span class="string">&lt;a href="http://example.com/elsie" class="sister" id="link1"&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;,</span></span><br><span class="line"><span class="string">&lt;a href="http://example.com/lacie" class="sister" id="link2"&gt;Lacie&lt;/a&gt; and</span></span><br><span class="line"><span class="string">&lt;a href="http://example.com/tillie" class="sister" id="link3"&gt;Tillie&lt;/a&gt;;</span></span><br><span class="line"><span class="string">and they lived at the bottom of a well.&lt;/p&gt;</span></span><br><span class="line"><span class="string">&lt;p class="story"&gt;...&lt;/p&gt;</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#创建 Beautiful Soup 对象</span></span><br><span class="line">soup = BeautifulSoup(html)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> soup.title</span><br><span class="line"><span class="comment"># &lt;title&gt;The Dormouse's story&lt;/title&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> soup.head</span><br><span class="line"><span class="comment"># &lt;head&gt;&lt;title&gt;The Dormouse's story&lt;/title&gt;&lt;/head&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> soup.a</span><br><span class="line"><span class="comment"># &lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> soup.p</span><br><span class="line"><span class="comment"># &lt;p class="title" name="dromouse"&gt;&lt;b&gt;The Dormouse's story&lt;/b&gt;&lt;/p&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> type(soup.p)</span><br><span class="line"><span class="comment"># &lt;class 'bs4.element.Tag'&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>我们可以利用 soup 加标签名轻松地获取这些标签的内容，这些对象的类型是bs4.element.Tag。但是注意，它查找的是在所有内容中的第一个符合要求的标签。如果要查询所有的标签，后面会进行介绍。<br><strong>对于 Tag，它有两个重要的属性，是 name 和 attrs</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">print</span> soup.name</span><br><span class="line"><span class="comment"># [document] #soup 对象本身比较特殊，它的 name 即为 [document]</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> soup.head.name</span><br><span class="line"><span class="comment"># head #对于其他内部标签，输出的值便为标签本身的名称</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> soup.p.attrs</span><br><span class="line"><span class="comment"># &#123;'class': ['title'], 'name': 'dromouse'&#125;</span></span><br><span class="line"><span class="comment"># 在这里，我们把 p 标签的所有属性打印输出了出来，得到的类型是一个字典。</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> soup.p[<span class="string">'class'</span>] <span class="comment"># soup.p.get('class')</span></span><br><span class="line"><span class="comment"># ['title'] #还可以利用get方法，传入属性的名称，二者是等价的</span></span><br><span class="line"></span><br><span class="line">soup.p[<span class="string">'class'</span>] = <span class="string">"newClass"</span></span><br><span class="line"><span class="keyword">print</span> soup.p <span class="comment"># 可以对这些属性和内容等等进行修改</span></span><br><span class="line"><span class="comment"># &lt;p class="newClass" name="dromouse"&gt;&lt;b&gt;The Dormouse's story&lt;/b&gt;&lt;/p&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">del</span> soup.p[<span class="string">'class'</span>] <span class="comment"># 还可以对这个属性进行删除</span></span><br><span class="line"><span class="keyword">print</span> soup.p</span><br><span class="line"><span class="comment"># &lt;p name="dromouse"&gt;&lt;b&gt;The Dormouse's story&lt;/b&gt;&lt;/p&gt;</span></span><br></pre></td></tr></table></figure></p>
<p><strong>2. NavigableString</strong><br>既然我们已经得到了标签的内容，那么问题来了，我们要想获取标签内部的文字怎么办呢？很简单，用 .string 即可，例如<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">print</span> soup.p.string</span><br><span class="line"><span class="comment"># The Dormouse's story</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> type(soup.p.string)</span><br><span class="line"><span class="comment"># In [13]: &lt;class 'bs4.element.NavigableString'&gt;</span></span><br></pre></td></tr></table></figure></p>
<p><strong>3. BeautifulSoup</strong><br>BeautifulSoup 对象表示的是一个文档的内容。大部分时候,可以把它当作 Tag 对象，是一个特殊的 Tag，我们可以分别获取它的类型，名称，以及属性来感受一下<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">print</span> type(soup.name)</span><br><span class="line"><span class="comment"># &lt;type 'unicode'&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> soup.name </span><br><span class="line"><span class="comment"># [document]</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> soup.attrs <span class="comment"># 文档本身的属性为空</span></span><br><span class="line"><span class="comment"># &#123;&#125;</span></span><br></pre></td></tr></table></figure></p>
<p><strong>4. Comment</strong><br>Comment 对象是一个特殊类型的 NavigableString 对象，其输出的内容不包括注释符号。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">print</span> soup.a</span><br><span class="line"><span class="comment"># &lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> soup.a.string</span><br><span class="line"><span class="comment"># Elsie </span></span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> type(soup.a.string)</span><br><span class="line"><span class="comment"># &lt;class 'bs4.element.Comment'&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>a 标签里的内容实际上是注释，但是如果我们利用 .string 来输出它的内容时，注释符号已经去掉了。</p>
<h2 id="遍历文档树"><a href="#遍历文档树" class="headerlink" title="遍历文档树"></a>遍历文档树</h2><p><strong>1. 直接子节点 ：.contents .children 属性</strong><br><strong>.content</strong><br>tag 的 .content 属性可以将tag的子节点以列表的方式输出<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">print</span> soup.head.contents </span><br><span class="line"><span class="comment">#[&lt;title&gt;The Dormouse's story&lt;/title&gt;]</span></span><br></pre></td></tr></table></figure></p>
<p>输出方式为列表，我们可以用列表索引来获取它的某一个元素<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">print</span> soup.head.contents[<span class="number">0</span>]</span><br><span class="line"><span class="comment">#&lt;title&gt;The Dormouse's story&lt;/title&gt;</span></span><br></pre></td></tr></table></figure></p>
<p><strong>.children</strong><br>它返回的不是一个 list，不过我们可以通过遍历获取所有子节点。</p>
<p>我们打印输出 .children 看一下，可以发现它是一个 list 生成器对象<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">print</span> soup.head.children</span><br><span class="line"><span class="comment">#&lt;listiterator object at 0x7f71457f5710&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> child <span class="keyword">in</span>  soup.body.children:</span><br><span class="line">    <span class="keyword">print</span> child</span><br></pre></td></tr></table></figure></p>
<p>结果：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&lt;p class="title" name="dromouse"&gt;&lt;b&gt;The Dormouse's story&lt;/b&gt;&lt;/p&gt;</span><br><span class="line"></span><br><span class="line">&lt;p class="story"&gt;Once upon a time there were three little sisters; and their names were</span><br><span class="line">&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;,</span><br><span class="line">&lt;a class="sister" href="http://example.com/lacie" id="link2"&gt;Lacie&lt;/a&gt; and</span><br><span class="line">&lt;a class="sister" href="http://example.com/tillie" id="link3"&gt;Tillie&lt;/a&gt;;</span><br><span class="line">and they lived at the bottom of a well.&lt;/p&gt;</span><br><span class="line"></span><br><span class="line">&lt;p class="story"&gt;...&lt;/p&gt;</span><br></pre></td></tr></table></figure></p>
<p><strong>2. 所有子孙节点: .descendants 属性</strong><br>.contents 和 .children 属性仅包含tag的直接子节点，.descendants 属性可以对所有tag的子孙节点进行递归循环，和 children类似，我们也需要遍历获取其中的内容。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> child <span class="keyword">in</span> soup.descendants:</span><br><span class="line">    <span class="keyword">print</span> child</span><br></pre></td></tr></table></figure></p>
<p>运行结果：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">&lt;html&gt;&lt;head&gt;&lt;title&gt;The Dormouse<span class="string">'s story&lt;/title&gt;&lt;/head&gt;</span></span><br><span class="line"><span class="string">&lt;body&gt;</span></span><br><span class="line">&lt;p class="title" name="dromouse"&gt;&lt;b&gt;The Dormouse's story&lt;/b&gt;&lt;/p&gt;</span><br><span class="line">&lt;p class="story"&gt;Once upon a time there were three little sisters; and their names were</span><br><span class="line">&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;,</span><br><span class="line">&lt;a class="sister" href="http://example.com/lacie" id="link2"&gt;Lacie&lt;/a&gt; and</span><br><span class="line">&lt;a class="sister" href="http://example.com/tillie" id="link3"&gt;Tillie&lt;/a&gt;;</span><br><span class="line">and they lived at the bottom of a well.&lt;/p&gt;</span><br><span class="line">&lt;p class="story"&gt;...&lt;/p&gt;</span><br><span class="line">&lt;/body&gt;&lt;/html&gt;</span><br><span class="line">&lt;head&gt;&lt;title&gt;The Dormouse<span class="string">'s story&lt;/title&gt;&lt;/head&gt;</span></span><br><span class="line">&lt;title&gt;The Dormouse's story&lt;/title&gt;</span><br><span class="line">The Dormouse<span class="string">'s story</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&lt;body&gt;</span></span><br><span class="line">&lt;p class="title" name="dromouse"&gt;&lt;b&gt;The Dormouse's story&lt;/b&gt;&lt;/p&gt;</span><br><span class="line">&lt;p class="story"&gt;Once upon a time there were three little sisters; and their names were</span><br><span class="line">&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;,</span><br><span class="line">&lt;a class="sister" href="http://example.com/lacie" id="link2"&gt;Lacie&lt;/a&gt; and</span><br><span class="line">&lt;a class="sister" href="http://example.com/tillie" id="link3"&gt;Tillie&lt;/a&gt;;</span><br><span class="line">and they lived at the bottom of a well.&lt;/p&gt;</span><br><span class="line">&lt;p class="story"&gt;...&lt;/p&gt;</span><br><span class="line">&lt;/body&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;p class="title" name="dromouse"&gt;&lt;b&gt;The Dormouse's story&lt;/b&gt;&lt;/p&gt;</span><br><span class="line">&lt;b&gt;The Dormouse<span class="string">'s story&lt;/b&gt;</span></span><br><span class="line"><span class="string">The Dormouse'</span>s story</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;p class="story"&gt;Once upon a time there were three little sisters; and their names were</span><br><span class="line">&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;,</span><br><span class="line">&lt;a class="sister" href="http://example.com/lacie" id="link2"&gt;Lacie&lt;/a&gt; and</span><br><span class="line">&lt;a class="sister" href="http://example.com/tillie" id="link3"&gt;Tillie&lt;/a&gt;;</span><br><span class="line">and they lived at the bottom of a well.&lt;/p&gt;</span><br><span class="line">Once upon a time there were three little sisters; <span class="keyword">and</span> their names were</span><br><span class="line"></span><br><span class="line">&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;</span><br><span class="line"> Elsie </span><br><span class="line">,</span><br><span class="line"></span><br><span class="line">&lt;a class="sister" href="http://example.com/lacie" id="link2"&gt;Lacie&lt;/a&gt;</span><br><span class="line">Lacie</span><br><span class="line"> <span class="keyword">and</span></span><br><span class="line"></span><br><span class="line">&lt;a class="sister" href="http://example.com/tillie" id="link3"&gt;Tillie&lt;/a&gt;</span><br><span class="line">Tillie</span><br><span class="line">;</span><br><span class="line"><span class="keyword">and</span> they lived at the bottom of a well.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&lt;p class="story"&gt;...&lt;/p&gt;</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<p><strong>3. 节点内容: .string 属性</strong><br>如果tag只有一个 NavigableString 类型子节点,那么这个tag可以使用 .string 得到子节点。如果一个tag仅有一个子节点,那么这个tag也可以使用 .string 方法,输出结果与当前唯一子节点的 .string 结果相同。</p>
<p>通俗点说就是：如果一个标签里面没有标签了，那么 .string 就会返回标签里面的内容。如果标签里面只有唯一的一个标签了，那么 .string 也会返回最里面的内容。例如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">print</span> soup.head.string</span><br><span class="line"><span class="comment">#The Dormouse's story</span></span><br><span class="line"><span class="keyword">print</span> soup.title.string</span><br><span class="line"><span class="comment">#The Dormouse's story</span></span><br></pre></td></tr></table></figure>
<h2 id="搜索文档树"><a href="#搜索文档树" class="headerlink" title="搜索文档树"></a>搜索文档树</h2><p><strong>1.find_all(name, attrs, recursive, text, \</strong>kwargs)<strong>
</strong>1）name 参数<strong><br>name 参数可以查找所有名字为 name 的tag,字符串对象会被自动忽略掉
</strong>A.传字符串**<br>最简单的过滤器是字符串.在搜索方法中传入一个字符串参数,Beautiful Soup会查找与字符串完整匹配的内容,下面的例子用于查找文档中所有的<b>标签:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">soup.find_all(<span class="string">'b'</span>)</span><br><span class="line"><span class="comment"># [&lt;b&gt;The Dormouse's story&lt;/b&gt;]</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> soup.find_all(<span class="string">'a'</span>)</span><br><span class="line"><span class="comment">#[&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;, &lt;a class="sister" href="http://example.com/lacie" id="link2"&gt;Lacie&lt;/a&gt;, &lt;a class="sister" href="http://example.com/tillie" id="link3"&gt;Tillie&lt;/a&gt;]</span></span><br></pre></td></tr></table></figure></b></p>
<p><strong>B.传正则表达式</strong><br>如果传入正则表达式作为参数,Beautiful Soup会通过正则表达式的 match() 来匹配内容.下面例子中找出所有以b开头的标签,这表示<body>和<b>标签都应该被找到<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">for</span> tag <span class="keyword">in</span> soup.find_all(re.compile(<span class="string">"^b"</span>)):</span><br><span class="line">    print(tag.name)</span><br><span class="line"><span class="comment"># body</span></span><br><span class="line"><span class="comment"># b</span></span><br></pre></td></tr></table></figure></b></body></p>
<p><strong>C.传列表</strong><br>如果传入列表参数,Beautiful Soup会将与列表中任一元素匹配的内容返回.下面代码找到文档中所有<a>标签和<b>标签:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">soup.find_all([<span class="string">"a"</span>, <span class="string">"b"</span>])</span><br><span class="line"><span class="comment"># [&lt;b&gt;The Dormouse's story&lt;/b&gt;,</span></span><br><span class="line"><span class="comment">#  &lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;Elsie&lt;/a&gt;,</span></span><br><span class="line"><span class="comment">#  &lt;a class="sister" href="http://example.com/lacie" id="link2"&gt;Lacie&lt;/a&gt;,</span></span><br><span class="line"><span class="comment">#  &lt;a class="sister" href="http://example.com/tillie" id="link3"&gt;Tillie&lt;/a&gt;]</span></span><br></pre></td></tr></table></figure></b></a></p>
<p><strong>2）keyword 参数</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">soup.find_all(id=<span class="string">'link2'</span>)</span><br><span class="line"><span class="comment"># [&lt;a class="sister" href="http://example.com/lacie" id="link2"&gt;Lacie&lt;/a&gt;]</span></span><br></pre></td></tr></table></figure></p>
<p><strong>3）text 参数</strong><br>通过 text 参数可以搜搜文档中的字符串内容，与 name 参数的可选值一样, text 参数接受 字符串 , 正则表达式 , 列表<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">soup.find_all(text=<span class="string">"Elsie"</span>)</span><br><span class="line"><span class="comment"># [u'Elsie']</span></span><br><span class="line"></span><br><span class="line">soup.find_all(text=[<span class="string">"Tillie"</span>, <span class="string">"Elsie"</span>, <span class="string">"Lacie"</span>])</span><br><span class="line"><span class="comment"># [u'Elsie', u'Lacie', u'Tillie']</span></span><br><span class="line"></span><br><span class="line">soup.find_all(text=re.compile(<span class="string">"Dormouse"</span>))</span><br><span class="line">[<span class="string">u"The Dormouse's story"</span>, <span class="string">u"The Dormouse's story"</span>]</span><br></pre></td></tr></table></figure></p>
<h2 id="CSS选择器"><a href="#CSS选择器" class="headerlink" title="CSS选择器"></a>CSS选择器</h2><p>这就是另一种与 find_all 方法有异曲同工之妙的查找方法.</p>
<ul>
<li><p>写 CSS 时，标签名不加任何修饰，类名前加.，id名前加#</p>
</li>
<li><p>在这里我们也可以利用类似的方法来筛选元素，用到的方法是 soup.select()，返回类型是 list<br><strong>（1）通过标签名查找</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">print</span> soup.select(<span class="string">'title'</span>) </span><br><span class="line"><span class="comment">#[&lt;title&gt;The Dormouse's story&lt;/title&gt;]</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> soup.select(<span class="string">'a'</span>)</span><br><span class="line"><span class="comment">#[&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;, &lt;a class="sister" href="http://example.com/lacie" id="link2"&gt;Lacie&lt;/a&gt;, &lt;a class="sister" href="http://example.com/tillie" id="link3"&gt;Tillie&lt;/a&gt;]</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> soup.select(<span class="string">'b'</span>)</span><br><span class="line"><span class="comment">#[&lt;b&gt;The Dormouse's story&lt;/b&gt;]</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><strong>（2）通过类名查找</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">print</span> soup.select(<span class="string">'.sister'</span>)</span><br><span class="line"><span class="comment">#[&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;, &lt;a class="sister" href="http://example.com/lacie" id="link2"&gt;Lacie&lt;/a&gt;, &lt;a class="sister" href="http://example.com/tillie" id="link3"&gt;Tillie&lt;/a&gt;]</span></span><br></pre></td></tr></table></figure></p>
<p><strong>（3）通过 id 名查找</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">print</span> soup.select(<span class="string">'#link1'</span>)</span><br><span class="line"><span class="comment">#[&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;]</span></span><br></pre></td></tr></table></figure></p>
<p><strong>（4）组合查找</strong><br>组合查找即和写 class 文件时，标签名与类名、id名进行的组合原理是一样的，例如查找 p 标签中，id 等于 link1的内容，二者需要用空格分开<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">print</span> soup.select(<span class="string">'p #link1'</span>)</span><br><span class="line"><span class="comment">#[&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;]</span></span><br></pre></td></tr></table></figure></p>
<p>直接子标签查找，则使用 &gt; 分隔<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">print</span> soup.select(<span class="string">"head &gt; title"</span>)</span><br><span class="line"><span class="comment">#[&lt;title&gt;The Dormouse's story&lt;/title&gt;]</span></span><br></pre></td></tr></table></figure></p>
<p><strong>（5）属性查找</strong><br>查找时还可以加入属性元素，属性需要用中括号括起来，注意属性和标签属于同一节点，所以中间不能加空格，否则会无法匹配到。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">print</span> soup.select(<span class="string">'a[class="sister"]'</span>)</span><br><span class="line"><span class="comment">#[&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;, &lt;a class="sister" href="http://example.com/lacie" id="link2"&gt;Lacie&lt;/a&gt;, &lt;a class="sister" href="http://example.com/tillie" id="link3"&gt;Tillie&lt;/a&gt;]</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> soup.select(<span class="string">'a[href="http://example.com/elsie"]'</span>)</span><br><span class="line"><span class="comment">#[&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;]</span></span><br></pre></td></tr></table></figure></p>
<p>同样，属性仍然可以与上述查找方式组合，不在同一节点的空格隔开，同一节点的不加空格<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">print</span> soup.select(<span class="string">'p a[href="http://example.com/elsie"]'</span>)</span><br><span class="line"><span class="comment">#[&lt;a class="sister" href="http://example.com/elsie" id="link1"&gt;&lt;!-- Elsie --&gt;&lt;/a&gt;]</span></span><br></pre></td></tr></table></figure></p>
<p><strong>(6) 获取内容</strong><br>以上的 select 方法返回的结果都是列表形式，可以遍历形式输出，然后用 get_text() 方法来获取它的内容。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">soup = BeautifulSoup(html, <span class="string">'lxml'</span>)</span><br><span class="line"><span class="keyword">print</span> type(soup.select(<span class="string">'title'</span>))</span><br><span class="line"><span class="keyword">print</span> soup.select(<span class="string">'title'</span>)[<span class="number">0</span>].get_text()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> title <span class="keyword">in</span> soup.select(<span class="string">'title'</span>):</span><br><span class="line">    <span class="keyword">print</span> title.get_text()</span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/10/2018051019/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mr.Q">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Dynamic-Soul">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/10/2018051019/" itemprop="url">案例：使用XPath的爬虫</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-10T19:18:06+08:00">2018-05-10</time>
            

            
            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/爬虫/" itemprop="url" rel="index"><span itemprop="name">爬虫</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="案例：使用XPath的爬虫"><a href="#案例：使用XPath的爬虫" class="headerlink" title="案例：使用XPath的爬虫"></a>案例：使用XPath的爬虫</h1><p>现在我们用XPath来做一个简单的爬虫，我们尝试爬取某个贴吧里的所有帖子，并且将该这个帖子里每个楼层发布的图片下载到本地。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># tieba_xpath.py</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> urllib</span><br><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Spider</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.tiebaName = raw_input(<span class="string">"请需要访问的贴吧："</span>)</span><br><span class="line">        self.beginPage = int(raw_input(<span class="string">"请输入起始页："</span>))</span><br><span class="line">        self.endPage = int(raw_input(<span class="string">"请输入终止页："</span>))</span><br><span class="line"></span><br><span class="line">        self.url = <span class="string">'http://tieba.baidu.com/f'</span></span><br><span class="line">        self.ua_header = &#123;<span class="string">"User-Agent"</span> : <span class="string">"Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1 Trident/5.0;"</span>&#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 图片编号</span></span><br><span class="line">        self.userName = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">tiebaSpider</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> page <span class="keyword">in</span> range(self.beginPage, self.endPage + <span class="number">1</span>):</span><br><span class="line">            pn = (page - <span class="number">1</span>) * <span class="number">50</span> <span class="comment"># page number</span></span><br><span class="line">            word = &#123;<span class="string">'pn'</span> : pn, <span class="string">'kw'</span>: self.tiebaName&#125;</span><br><span class="line"></span><br><span class="line">            word = urllib.urlencode(word) <span class="comment">#转换成url编码格式（字符串）</span></span><br><span class="line">            myUrl = self.url + <span class="string">"?"</span> + word</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 示例：http://tieba.baidu.com/f? kw=%E7%BE%8E%E5%A5%B3 &amp; pn=50</span></span><br><span class="line">            <span class="comment"># 调用 页面处理函数 load_Page</span></span><br><span class="line">            <span class="comment"># 并且获取页面所有帖子链接,</span></span><br><span class="line">            links = self.loadPage(myUrl)  <span class="comment"># urllib2_test3.py</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 读取页面内容</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">loadPage</span><span class="params">(self, url)</span>:</span></span><br><span class="line">        req = urllib2.Request(url, headers = self.ua_header)</span><br><span class="line">        html = urllib2.urlopen(req).read()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 解析html 为 HTML 文档</span></span><br><span class="line">        selector=etree.HTML(html)</span><br><span class="line"></span><br><span class="line">        <span class="comment">#抓取当前页面的所有帖子的url的后半部分，也就是帖子编号</span></span><br><span class="line">        <span class="comment"># http://tieba.baidu.com/p/4884069807里的 “p/4884069807”</span></span><br><span class="line">        links = selector.xpath(<span class="string">'//div[@class="threadlist_lz clearfix"]/div/a/@href'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># links 类型为 etreeElementString 列表</span></span><br><span class="line">        <span class="comment"># 遍历列表，并且合并成一个帖子地址，调用 图片处理函数 loadImage</span></span><br><span class="line">        <span class="keyword">for</span> link <span class="keyword">in</span> links:</span><br><span class="line">            link = <span class="string">"http://tieba.baidu.com"</span> + link</span><br><span class="line">            self.loadImages(link)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 获取图片</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">loadImages</span><span class="params">(self, link)</span>:</span></span><br><span class="line">        req = urllib2.Request(link, headers = self.ua_header)</span><br><span class="line">        html = urllib2.urlopen(req).read()</span><br><span class="line"></span><br><span class="line">        selector = etree.HTML(html)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 获取这个帖子里所有图片的src路径</span></span><br><span class="line">        imagesLinks = selector.xpath(<span class="string">'//img[@class="BDE_Image"]/@src'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 依次取出图片路径，下载保存</span></span><br><span class="line">        <span class="keyword">for</span> imagesLink <span class="keyword">in</span> imagesLinks:</span><br><span class="line">            self.writeImages(imagesLink)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 保存页面内容</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">writeImages</span><span class="params">(self, imagesLink)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">            将 images 里的二进制内容存入到 userNname 文件中</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">print</span> imagesLink</span><br><span class="line">        <span class="keyword">print</span> <span class="string">"正在存储文件 %d ..."</span> % self.userName</span><br><span class="line">        <span class="comment"># 1. 打开文件，返回一个文件对象</span></span><br><span class="line">        file = open(<span class="string">'./images/'</span> + str(self.userName)  + <span class="string">'.png'</span>, <span class="string">'wb'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 2. 获取图片里的内容</span></span><br><span class="line">        images = urllib2.urlopen(imagesLink).read()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 3. 调用文件对象write() 方法，将page_html的内容写入到文件里</span></span><br><span class="line">        file.write(images)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 4. 最后关闭文件</span></span><br><span class="line">        file.close()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 计数器自增1</span></span><br><span class="line">        self.userName += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 模拟 main 函数</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 首先创建爬虫对象</span></span><br><span class="line">    mySpider = Spider()</span><br><span class="line">    <span class="comment"># 调用爬虫对象的方法，开始工作</span></span><br><span class="line">    mySpider.tiebaSpider()</span><br></pre></td></tr></table></figure></p>
<img src="/2018/05/10/2018051019/1.jpg">
          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/09/2018050922/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mr.Q">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Dynamic-Soul">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/09/2018050922/" itemprop="url">XPath与lxnl类库</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-09T22:23:46+08:00">2018-05-09</time>
            

            
            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/爬虫/" itemprop="url" rel="index"><span itemprop="name">爬虫</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>正则用的不好，处理HTML文档很累，有没有其他的方法？</p>
<h2 id="有！那就是XPath，我们可以先将-HTML文件-转换成-XML文档，然后用-XPath-查找-HTML-节点或元素。"><a href="#有！那就是XPath，我们可以先将-HTML文件-转换成-XML文档，然后用-XPath-查找-HTML-节点或元素。" class="headerlink" title="有！那就是XPath，我们可以先将 HTML文件 转换成 XML文档，然后用 XPath 查找 HTML 节点或元素。"></a>有！那就是XPath，我们可以先将 HTML文件 转换成 XML文档，然后用 XPath 查找 HTML 节点或元素。</h2><h1 id="什么是XML"><a href="#什么是XML" class="headerlink" title="什么是XML"></a>什么是XML</h1><ul>
<li>XML 指可扩展标记语言（EXtensible Markup Language）</li>
<li>XML 是一种标记语言，很类似 HTML</li>
<li>XML 的设计宗旨是传输数据，而非显示数据</li>
<li>XML 的标签需要我们自行定义。</li>
<li>XML 被设计为具有自我描述性。</li>
<li>XML 是 W3C 的推荐标准</li>
</ul>
<p>W3School官方文档：<a href="http://www.w3school.com.cn/xml/index.asp" target="_blank" rel="noopener">http://www.w3school.com.cn/xml/index.asp</a></p>
<h2 id="XML-和-HTML-的区别"><a href="#XML-和-HTML-的区别" class="headerlink" title="XML 和 HTML 的区别"></a>XML 和 HTML 的区别</h2><table>
<thead>
<tr>
<th>数据格式</th>
<th style="text-align:right">描述</th>
<th style="text-align:center">设计目标</th>
</tr>
</thead>
<tbody>
<tr>
<td>XML</td>
<td style="text-align:right">Extensible Markup Language （可扩展标记语言）</td>
<td style="text-align:center">被设计为传输和存储数据，其焦点是数据的内容。</td>
</tr>
<tr>
<td>HTML</td>
<td style="text-align:right">HyperText Markup Language （超文本标记语言）</td>
<td style="text-align:center">显示数据以及如何更好显示数据。</td>
</tr>
<tr>
<td>HTML DOM</td>
<td style="text-align:right">Document Object Model for HTML (文档对象模型)</td>
<td style="text-align:center">通过 HTML DOM，可以访问所有的 HTML 元素，连同它们所包含的文本和属性。可以对其中的内容进行修改和删除，同时也可以创建新的元素。</td>
</tr>
</tbody>
</table>
<h3 id="XML文档示例"><a href="#XML文档示例" class="headerlink" title="XML文档示例"></a>XML文档示例</h3><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version="1.0" encoding="utf-8"?&gt;</span><br><span class="line"></span><br><span class="line">&lt;bookstore&gt; </span><br><span class="line"></span><br><span class="line">  &lt;book category=<span class="string">"cooking"</span>&gt; </span><br><span class="line">    &lt;title lang="en"&gt;Everyday Italian&lt;/title&gt;  </span><br><span class="line">    &lt;author&gt;Giada De Laurentiis&lt;/author&gt;  </span><br><span class="line">    &lt;year&gt;2005&lt;/year&gt;  </span><br><span class="line">    &lt;price&gt;30.00&lt;/price&gt; </span><br><span class="line">  &lt;/book&gt;  </span><br><span class="line"></span><br><span class="line">  &lt;book category=<span class="string">"children"</span>&gt; </span><br><span class="line">    &lt;title lang="en"&gt;Harry Potter&lt;/title&gt;  </span><br><span class="line">    &lt;author&gt;J K. Rowling&lt;/author&gt;  </span><br><span class="line">    &lt;year&gt;2005&lt;/year&gt;  </span><br><span class="line">    &lt;price&gt;29.99&lt;/price&gt; </span><br><span class="line">  &lt;/book&gt;  </span><br><span class="line"></span><br><span class="line">  &lt;book category=<span class="string">"web"</span>&gt; </span><br><span class="line">    &lt;title lang="en"&gt;XQuery Kick Start&lt;/title&gt;  </span><br><span class="line">    &lt;author&gt;James McGovern&lt;/author&gt;  </span><br><span class="line">    &lt;author&gt;Per Bothner&lt;/author&gt;  </span><br><span class="line">    &lt;author&gt;Kurt Cagle&lt;/author&gt;  </span><br><span class="line">    &lt;author&gt;James Linn&lt;/author&gt;  </span><br><span class="line">    &lt;author&gt;Vaidyanathan Nagarajan&lt;/author&gt;  </span><br><span class="line">    &lt;year&gt;2003&lt;/year&gt;  </span><br><span class="line">    &lt;price&gt;49.99&lt;/price&gt; </span><br><span class="line">  &lt;/book&gt; </span><br><span class="line"></span><br><span class="line">  &lt;book category=<span class="string">"web"</span> cover=<span class="string">"paperback"</span>&gt; </span><br><span class="line">    &lt;title lang="en"&gt;Learning XML&lt;/title&gt;  </span><br><span class="line">    &lt;author&gt;Erik T. Ray&lt;/author&gt;  </span><br><span class="line">    &lt;year&gt;2003&lt;/year&gt;  </span><br><span class="line">    &lt;price&gt;39.95&lt;/price&gt; </span><br><span class="line">  &lt;/book&gt; </span><br><span class="line"></span><br><span class="line">&lt;/bookstore&gt;</span><br></pre></td></tr></table></figure>
<h3 id="HTML-DOM-模型示例"><a href="#HTML-DOM-模型示例" class="headerlink" title="HTML DOM 模型示例"></a>HTML DOM 模型示例</h3><p>HTML DOM 定义了访问和操作 HTML 文档的标准方法，以树结构方式表达 HTML 文档。</p>
<img src="/2018/05/09/2018050922/1.jpg">
<hr>
<h2 id="XML的节点关系"><a href="#XML的节点关系" class="headerlink" title="XML的节点关系"></a>XML的节点关系</h2><p><strong>1. 父（Parent）</strong><br>每个元素以及属性都有一个父。</p>
<p>下面是一个简单的XML例子中，book 元素是 title、author、year 以及 price 元素的父：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version="1.0" encoding="utf-8"?&gt;</span><br><span class="line"></span><br><span class="line">&lt;book&gt;</span><br><span class="line">  &lt;title&gt;Harry Potter&lt;/title&gt;</span><br><span class="line">  &lt;author&gt;J K. Rowling&lt;/author&gt;</span><br><span class="line">  &lt;year&gt;2005&lt;/year&gt;</span><br><span class="line">  &lt;price&gt;29.99&lt;/price&gt;</span><br><span class="line">&lt;/book&gt;</span><br></pre></td></tr></table></figure></p>
<p><strong>2. 子（Children）</strong><br>元素节点可有零个、一个或多个子。</p>
<p>在下面的例子中，title、author、year 以及 price 元素都是 book 元素的子：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version="1.0" encoding="utf-8"?&gt;</span><br><span class="line"></span><br><span class="line">&lt;book&gt;</span><br><span class="line">  &lt;title&gt;Harry Potter&lt;/title&gt;</span><br><span class="line">  &lt;author&gt;J K. Rowling&lt;/author&gt;</span><br><span class="line">  &lt;year&gt;2005&lt;/year&gt;</span><br><span class="line">  &lt;price&gt;29.99&lt;/price&gt;</span><br><span class="line">&lt;/book&gt;</span><br></pre></td></tr></table></figure></p>
<p><strong>3. 同胞（Sibling）</strong><br>拥有相同的父的节点</p>
<p>在下面的例子中，title、author、year 以及 price 元素都是同胞：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version="1.0" encoding="utf-8"?&gt;</span><br><span class="line"></span><br><span class="line">&lt;book&gt;</span><br><span class="line">  &lt;title&gt;Harry Potter&lt;/title&gt;</span><br><span class="line">  &lt;author&gt;J K. Rowling&lt;/author&gt;</span><br><span class="line">  &lt;year&gt;2005&lt;/year&gt;</span><br><span class="line">  &lt;price&gt;29.99&lt;/price&gt;</span><br><span class="line">&lt;/book&gt;</span><br></pre></td></tr></table></figure></p>
<p><strong>4. 先辈（Ancestor）</strong><br>某节点的父、父的父，等等。</p>
<p>在下面的例子中，title 元素的先辈是 book 元素和 bookstore 元素：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version="1.0" encoding="utf-8"?&gt;</span><br><span class="line"></span><br><span class="line">&lt;bookstore&gt;</span><br><span class="line"></span><br><span class="line">&lt;book&gt;</span><br><span class="line">  &lt;title&gt;Harry Potter&lt;/title&gt;</span><br><span class="line">  &lt;author&gt;J K. Rowling&lt;/author&gt;</span><br><span class="line">  &lt;year&gt;2005&lt;/year&gt;</span><br><span class="line">  &lt;price&gt;29.99&lt;/price&gt;</span><br><span class="line">&lt;/book&gt;</span><br><span class="line"></span><br><span class="line">&lt;/bookstore&gt;</span><br></pre></td></tr></table></figure></p>
<p><strong>5. 后代（Descendant）</strong><br>某个节点的子，子的子，等等。</p>
<p>在下面的例子中，bookstore 的后代是 book、title、author、year 以及 price 元素：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version="1.0" encoding="utf-8"?&gt;</span><br><span class="line"></span><br><span class="line">&lt;bookstore&gt;</span><br><span class="line"></span><br><span class="line">&lt;book&gt;</span><br><span class="line">  &lt;title&gt;Harry Potter&lt;/title&gt;</span><br><span class="line">  &lt;author&gt;J K. Rowling&lt;/author&gt;</span><br><span class="line">  &lt;year&gt;2005&lt;/year&gt;</span><br><span class="line">  &lt;price&gt;29.99&lt;/price&gt;</span><br><span class="line">&lt;/book&gt;</span><br><span class="line"></span><br><span class="line">&lt;/bookstore&gt;</span><br></pre></td></tr></table></figure></p>
<h1 id="什么是XPath？"><a href="#什么是XPath？" class="headerlink" title="什么是XPath？"></a>什么是XPath？</h1><pre><code>XPath (XML Path Language) 是一门在 XML 文档中查找信息的语言，可用来在 XML 文档中对元素和属性进行遍历。

W3School官方文档：http://www.w3school.com.cn/xpath/index.asp
</code></pre><h2 id="XPath-开发工具"><a href="#XPath-开发工具" class="headerlink" title="XPath 开发工具"></a>XPath 开发工具</h2><ol>
<li>开源的XPath表达式编辑工具:XMLQuire(XML格式文件可用)</li>
<li>Chrome插件 XPath Helper</li>
<li>Firefox插件 XPath Checker<h2 id="选取节点"><a href="#选取节点" class="headerlink" title="选取节点"></a>选取节点</h2>XPath 使用路径表达式来选取 XML 文档中的节点或者节点集。这些路径表达式和我们在常规的电脑文件系统中看到的表达式非常相似。</li>
</ol>
<p>下面列出了最常用的路径表达式：</p>
<table>
<thead>
<tr>
<th></th>
<th>路径表达式</th>
</tr>
</thead>
<tbody>
<tr>
<td>bookstore</td>
<td>选取 bookstore 元素的所有子节点。</td>
</tr>
<tr>
<td>/bookstore</td>
<td>选取根元素 bookstore。注释：假如路径起始于正斜杠( / )，则此路径始终代表到某元素的绝对路径！</td>
</tr>
<tr>
<td>bookstore/book</td>
<td>选取属于 bookstore 的子元素的所有 book 元素。</td>
</tr>
<tr>
<td>//book</td>
<td>选取所有 book 子元素，而不管它们在文档中的位置。</td>
</tr>
<tr>
<td>bookstore//book</td>
<td>选择属于 bookstore 元素的后代的所有 book 元素，而不管它们位于 bookstore 之下的什么位置。</td>
</tr>
<tr>
<td>//@lang</td>
<td>选取名为 lang 的所有属性。</td>
</tr>
</tbody>
</table>
<h2 id="谓语（Predicates）"><a href="#谓语（Predicates）" class="headerlink" title="谓语（Predicates）"></a>谓语（Predicates）</h2><p>谓语用来查找某个特定的节点或者包含某个指定的值的节点，被嵌在方括号中。</p>
<p>在下面的表格中，我们列出了带有谓语的一些路径表达式，以及表达式的结果：</p>
<table>
<thead>
<tr>
<th>路径表达式</th>
<th>结果</th>
</tr>
</thead>
<tbody>
<tr>
<td>/bookstore/book[1]</td>
<td>选取属于 bookstore 子元素的第一个 book 元素。</td>
</tr>
<tr>
<td>/bookstore/book[last()]</td>
<td>选取属于 bookstore 子元素的最后一个 book 元素。</td>
</tr>
<tr>
<td>/bookstore/book[last()-1]</td>
<td>选取属于 bookstore 子元素的倒数第二个 book 元素。</td>
</tr>
<tr>
<td>/bookstore/book[position()&lt;3]</td>
<td>选取最前面的两个属于 bookstore 元素的子元素的 book 元素。</td>
</tr>
<tr>
<td>//title[@lang]</td>
<td>选取所有拥有名为 lang 的属性的 title 元素。</td>
</tr>
<tr>
<td>//title[@lang=’eng’]</td>
<td>选取所有 title 元素，且这些元素拥有值为 eng 的 lang 属性。</td>
</tr>
<tr>
<td>/bookstore/book[price&gt;35.00]</td>
<td>选取 bookstore 元素的所有 book 元素，且其中的 price 元素的值须大于 35.00。</td>
</tr>
<tr>
<td>/bookstore/book[price&gt;35.00]/title</td>
<td>选取 bookstore 元素中的 book 元素的所有 title 元素，且其中的 price 元素的值须大于 35.00。</td>
</tr>
</tbody>
</table>
<h2 id="选取未知节点"><a href="#选取未知节点" class="headerlink" title="选取未知节点"></a>选取未知节点</h2><p>XPath 通配符可用来选取未知的 XML 元素。</p>
<table>
<thead>
<tr>
<th>通配符</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>*</td>
<td>匹配任何元素节点。</td>
</tr>
<tr>
<td>@*</td>
<td>匹配任何属性节点。</td>
</tr>
<tr>
<td>node()</td>
<td>匹配任何类型的节点。</td>
</tr>
</tbody>
</table>
<p>在下面的表格中，我们列出了一些路径表达式，以及这些表达式的结果：</p>
<table>
<thead>
<tr>
<th>路径表达式</th>
<th>结果</th>
</tr>
</thead>
<tbody>
<tr>
<td>/bookstore/*</td>
<td>选取 bookstore 元素的所有子元素。</td>
</tr>
<tr>
<td>//*</td>
<td>选取文档中的所有元素。</td>
</tr>
<tr>
<td>//title[@*]</td>
<td>选取所有带有属性的 title 元素。</td>
</tr>
</tbody>
</table>
<h2 id="选取若干路径"><a href="#选取若干路径" class="headerlink" title="选取若干路径"></a>选取若干路径</h2><p>通过在路径表达式中使用“|”运算符，您可以选取若干个路径。</p>
<p>实例</p>
<p>在下面的表格中，我们列出了一些路径表达式，以及这些表达式的结果：</p>
<table>
<thead>
<tr>
<th>路径表达式</th>
<th>结果</th>
</tr>
</thead>
<tbody>
<tr>
<td>//book/title  //book/price</td>
<td>选取 book 元素的所有 title 和 price 元素。</td>
</tr>
<tr>
<td>//title  //price</td>
<td>选取文档中的所有 title 和 price 元素。</td>
</tr>
<tr>
<td>/bookstore/book/title  //price</td>
<td>选取属于 bookstore 元素的 book 元素的所有 title 元素，以及文档中所有的 price 元素。</td>
</tr>
</tbody>
</table>
<h2 id="XPath的运算符"><a href="#XPath的运算符" class="headerlink" title="XPath的运算符"></a>XPath的运算符</h2><p>下面列出了可用在 XPath 表达式中的运算符：</p>
<img src="/2018/05/09/2018050922/2.jpg">
<p><strong>这些就是XPath的语法内容，在运用到Python抓取时要先转换为xml。</strong></p>
<h1 id="lxml库"><a href="#lxml库" class="headerlink" title="lxml库"></a>lxml库</h1><pre><code>lxml 是 一个HTML/XML的解析器，主要的功能是如何解析和提取 HTML/XML 数据。

lxml和正则一样，也是用 C 实现的，是一款高性能的 Python HTML/XML 解析器，我们可以利用之前学习的XPath语法，来快速的定位特定元素以及节点信息。

lxml python 官方文档：http://lxml.de/index.html

需要安装C语言库，可使用 pip 安装：pip install lxml （或通过wheel方式安装）
</code></pre><h2 id="初步使用"><a href="#初步使用" class="headerlink" title="初步使用"></a>初步使用</h2><p>我们利用它来解析 HTML 代码，简单示例：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># lxml_test.py</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 lxml 的 etree 库</span></span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree </span><br><span class="line"></span><br><span class="line">text = <span class="string">'''</span></span><br><span class="line"><span class="string">&lt;div&gt;</span></span><br><span class="line"><span class="string">    &lt;ul&gt;</span></span><br><span class="line"><span class="string">         &lt;li class="item-0"&gt;&lt;a href="link1.html"&gt;first item&lt;/a&gt;&lt;/li&gt;</span></span><br><span class="line"><span class="string">         &lt;li class="item-1"&gt;&lt;a href="link2.html"&gt;second item&lt;/a&gt;&lt;/li&gt;</span></span><br><span class="line"><span class="string">         &lt;li class="item-inactive"&gt;&lt;a href="link3.html"&gt;third item&lt;/a&gt;&lt;/li&gt;</span></span><br><span class="line"><span class="string">         &lt;li class="item-1"&gt;&lt;a href="link4.html"&gt;fourth item&lt;/a&gt;&lt;/li&gt;</span></span><br><span class="line"><span class="string">         &lt;li class="item-0"&gt;&lt;a href="link5.html"&gt;fifth item&lt;/a&gt; # 注意，此处缺少一个 &lt;/li&gt; 闭合标签</span></span><br><span class="line"><span class="string">     &lt;/ul&gt;</span></span><br><span class="line"><span class="string"> &lt;/div&gt;</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#利用etree.HTML，将字符串解析为HTML文档</span></span><br><span class="line">html = etree.HTML(text) </span><br><span class="line"></span><br><span class="line"><span class="comment"># 按字符串序列化HTML文档</span></span><br><span class="line">result = etree.tostring(html) </span><br><span class="line"></span><br><span class="line">print(result)</span><br></pre></td></tr></table></figure></p>
<p>输出结果：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;html&gt;&lt;body&gt;</span><br><span class="line">&lt;div&gt;</span><br><span class="line">    &lt;ul&gt;</span><br><span class="line">         &lt;li class="item-0"&gt;&lt;a href="link1.html"&gt;first item&lt;/a&gt;&lt;/li&gt;</span><br><span class="line">         &lt;li class="item-1"&gt;&lt;a href="link2.html"&gt;second item&lt;/a&gt;&lt;/li&gt;</span><br><span class="line">         &lt;li class="item-inactive"&gt;&lt;a href="link3.html"&gt;third item&lt;/a&gt;&lt;/li&gt;</span><br><span class="line">         &lt;li class="item-1"&gt;&lt;a href="link4.html"&gt;fourth item&lt;/a&gt;&lt;/li&gt;</span><br><span class="line">         &lt;li class="item-0"&gt;&lt;a href="link5.html"&gt;fifth item&lt;/a&gt;&lt;/li&gt;</span><br><span class="line">&lt;/ul&gt;</span><br><span class="line"> &lt;/div&gt;</span><br><span class="line">&lt;/body&gt;&lt;/html&gt;</span><br></pre></td></tr></table></figure></p>
<p>lxml 可以自动修正 html 代码，例子里不仅补全了 li 标签，还添加了 body，html 标签。</p>
<h2 id="文件读取："><a href="#文件读取：" class="headerlink" title="文件读取："></a>文件读取：</h2><p>除了直接读取字符串，lxml还支持从文件里读取内容。我们新建一个hello.html文件：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- hello.html --&gt;</span><br><span class="line"></span><br><span class="line">&lt;div&gt;</span><br><span class="line">    &lt;ul&gt;</span><br><span class="line">         &lt;li class="item-0"&gt;&lt;a href="link1.html"&gt;first item&lt;/a&gt;&lt;/li&gt;</span><br><span class="line">         &lt;li class="item-1"&gt;&lt;a href="link2.html"&gt;second item&lt;/a&gt;&lt;/li&gt;</span><br><span class="line">         &lt;li class="item-inactive"&gt;&lt;a href="link3.html"&gt;&lt;span class="bold"&gt;third item&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;</span><br><span class="line">         &lt;li class="item-1"&gt;&lt;a href="link4.html"&gt;fourth item&lt;/a&gt;&lt;/li&gt;</span><br><span class="line">         &lt;li class="item-0"&gt;&lt;a href="link5.html"&gt;fifth item&lt;/a&gt;&lt;/li&gt;</span><br><span class="line">     &lt;/ul&gt;</span><br><span class="line"> &lt;/div&gt;</span><br></pre></td></tr></table></figure></p>
<p>再利用 etree.parse() 方法来读取文件。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># lxml_parse.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取外部文件 hello.html</span></span><br><span class="line">html = etree.parse(<span class="string">'./hello.html'</span>)</span><br><span class="line">result = etree.tostring(html, pretty_print=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">print(result)</span><br></pre></td></tr></table></figure></p>
<p>输出结果与之前相同：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&lt;html&gt;&lt;body&gt;</span><br><span class="line">&lt;div&gt;</span><br><span class="line">    &lt;ul&gt;</span><br><span class="line">         &lt;li class="item-0"&gt;&lt;a href="link1.html"&gt;first item&lt;/a&gt;&lt;/li&gt;</span><br><span class="line">         &lt;li class="item-1"&gt;&lt;a href="link2.html"&gt;second item&lt;/a&gt;&lt;/li&gt;</span><br><span class="line">         &lt;li class="item-inactive"&gt;&lt;a href="link3.html"&gt;third item&lt;/a&gt;&lt;/li&gt;</span><br><span class="line">         &lt;li class="item-1"&gt;&lt;a href="link4.html"&gt;fourth item&lt;/a&gt;&lt;/li&gt;</span><br><span class="line">         &lt;li class="item-0"&gt;&lt;a href="link5.html"&gt;fifth item&lt;/a&gt;&lt;/li&gt;</span><br><span class="line">&lt;/ul&gt;</span><br><span class="line"> &lt;/div&gt;</span><br><span class="line">&lt;/body&gt;&lt;/html&gt;</span><br></pre></td></tr></table></figure></p>
<h2 id="XPath实例测试"><a href="#XPath实例测试" class="headerlink" title="XPath实例测试"></a>XPath实例测试</h2><p><strong>1. 获取所有的 <li> 标签</li></strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># xpath_li.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line">html = etree.parse(<span class="string">'hello.html'</span>)</span><br><span class="line"><span class="keyword">print</span> type(html)  <span class="comment"># 显示etree.parse() 返回类型</span></span><br><span class="line"></span><br><span class="line">result = html.xpath(<span class="string">'//li'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> result  <span class="comment"># 打印&lt;li&gt;标签的元素集合</span></span><br><span class="line"><span class="keyword">print</span> len(result)</span><br><span class="line"><span class="keyword">print</span> type(result)</span><br><span class="line"><span class="keyword">print</span> type(result[<span class="number">0</span>])</span><br></pre></td></tr></table></figure></p>
<p>输出结果：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;type <span class="string">'lxml.etree._ElementTree'</span>&gt;</span><br><span class="line">[&lt;Element li at <span class="number">0x1014e0e18</span>&gt;, &lt;Element li at <span class="number">0x1014e0ef0</span>&gt;, &lt;Element li at <span class="number">0x1014e0f38</span>&gt;, &lt;Element li at <span class="number">0x1014e0f80</span>&gt;, &lt;Element li at <span class="number">0x1014e0fc8</span>&gt;]</span><br><span class="line"><span class="number">5</span></span><br><span class="line">&lt;type <span class="string">'list'</span>&gt;</span><br><span class="line">&lt;type <span class="string">'lxml.etree._Element'</span>&gt;</span><br></pre></td></tr></table></figure></p>
<p><strong>2. 继续获取<li> 标签的所有 class属性</li></strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># xpath_li.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line">html = etree.parse(<span class="string">'hello.html'</span>)</span><br><span class="line">result = html.xpath(<span class="string">'//li/@class'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> result</span><br></pre></td></tr></table></figure></p>
<p>运行结果<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">'item-0'</span>, <span class="string">'item-1'</span>, <span class="string">'item-inactive'</span>, <span class="string">'item-1'</span>, <span class="string">'item-0'</span>]</span><br></pre></td></tr></table></figure></p>
<p><strong>3. 继续获取<li>标签下hre 为 link1.html 的 <a> 标签</a></li></strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># xpath_li.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line">html = etree.parse(<span class="string">'hello.html'</span>)</span><br><span class="line">result = html.xpath(<span class="string">'//li/a[@href="link1.html"]'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> result</span><br></pre></td></tr></table></figure></p>
<p>运行结果<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&lt;Element a at <span class="number">0x10ffaae18</span>&gt;]</span><br></pre></td></tr></table></figure></p>
<p><strong>4. 获取<li> 标签下的所有 <span> 标签</span></li></strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># xpath_li.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line">html = etree.parse(<span class="string">'hello.html'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#result = html.xpath('//li/span')</span></span><br><span class="line"><span class="comment">#注意这么写是不对的：</span></span><br><span class="line"><span class="comment">#因为 / 是用来获取子元素的，而 &lt;span&gt; 并不是 &lt;li&gt; 的子元素，所以，要用双斜杠</span></span><br><span class="line"></span><br><span class="line">result = html.xpath(<span class="string">'//li//span'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> result</span><br></pre></td></tr></table></figure></p>
<p>运行结果<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&lt;Element span at <span class="number">0x10d698e18</span>&gt;]</span><br></pre></td></tr></table></figure></p>
<p><strong>5. 获取 <li> 标签下的<a>标签里的所有 class</a></li></strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># xpath_li.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line">html = etree.parse(<span class="string">'hello.html'</span>)</span><br><span class="line">result = html.xpath(<span class="string">'//li/a//@class'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> result</span><br></pre></td></tr></table></figure></p>
<p>运行结果<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">'blod'</span>]</span><br></pre></td></tr></table></figure></p>
<p><strong>6. 获取最后一个 <li> 的 <a> 的 href</a></li></strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># xpath_li.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line">html = etree.parse(<span class="string">'hello.html'</span>)</span><br><span class="line"></span><br><span class="line">result = html.xpath(<span class="string">'//li[last()]/a/@href'</span>)</span><br><span class="line"><span class="comment"># 谓语 [last()] 可以找到最后一个元素</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> result</span><br></pre></td></tr></table></figure></p>
<p>运行结果<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">'link5.html'</span>]</span><br></pre></td></tr></table></figure></p>
<p><strong>7. 获取倒数第二个元素的内容</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># xpath_li.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line">html = etree.parse(<span class="string">'hello.html'</span>)</span><br><span class="line">result = html.xpath(<span class="string">'//li[last()-1]/a'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># text 方法可以获取元素内容</span></span><br><span class="line"><span class="keyword">print</span> result[<span class="number">0</span>].text</span><br></pre></td></tr></table></figure></p>
<p>运行结果<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fourth item</span><br></pre></td></tr></table></figure></p>
<p><strong>8. 获取 class 值为 bold 的标签名</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># xpath_li.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line">html = etree.parse(<span class="string">'hello.html'</span>)</span><br><span class="line"></span><br><span class="line">result = html.xpath(<span class="string">'//*[@class="bold"]'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># tag方法可以获取标签名</span></span><br><span class="line"><span class="keyword">print</span> result[<span class="number">0</span>].tag</span><br></pre></td></tr></table></figure></p>
<p>运行结果<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">span</span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/08/2018050822/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mr.Q">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Dynamic-Soul">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/08/2018050822/" itemprop="url">案例：使用正则表达式的爬虫</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-08T22:32:33+08:00">2018-05-08</time>
            

            
            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/爬虫/" itemprop="url" rel="index"><span itemprop="name">爬虫</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="案例：使用正则表达式的爬虫"><a href="#案例：使用正则表达式的爬虫" class="headerlink" title="案例：使用正则表达式的爬虫"></a>案例：使用正则表达式的爬虫</h1><p>现在拥有了正则表达式这把神兵利器，我们就可以进行对爬取到的全部网页源代码进行筛选了。</p>
<p>下面我们一起尝试一下爬取内涵段子网站： <a href="http://www.neihan8.com/article/list_5_1.html" target="_blank" rel="noopener">http://www.neihan8.com/article/list_5_1.html</a></p>
<p>打开之后，不难看到里面一个一个灰常有内涵的段子，当你进行翻页的时候，注意url地址的变化：</p>
<ul>
<li><p>第一页url: http: //<a href="http://www.neihan8.com/article/list_5_1" target="_blank" rel="noopener">www.neihan8.com/article/list_5_1</a> .html</p>
</li>
<li><p>第二页url: http: //<a href="http://www.neihan8.com/article/list_5_2" target="_blank" rel="noopener">www.neihan8.com/article/list_5_2</a> .html</p>
</li>
<li><p>第三页url: http: //<a href="http://www.neihan8.com/article/list_5_3" target="_blank" rel="noopener">www.neihan8.com/article/list_5_3</a> .html</p>
</li>
<li><p>第四页url: http: //<a href="http://www.neihan8.com/article/list_5_4" target="_blank" rel="noopener">www.neihan8.com/article/list_5_4</a> .html</p>
</li>
</ul>
<h2 id="这样我们的url规律找到了，要想爬取所有的段子，只需要修改一个参数即可。-下面我们就开始一步一步将所有的段子爬取下来吧。"><a href="#这样我们的url规律找到了，要想爬取所有的段子，只需要修改一个参数即可。-下面我们就开始一步一步将所有的段子爬取下来吧。" class="headerlink" title="这样我们的url规律找到了，要想爬取所有的段子，只需要修改一个参数即可。 下面我们就开始一步一步将所有的段子爬取下来吧。"></a>这样我们的url规律找到了，要想爬取所有的段子，只需要修改一个参数即可。 下面我们就开始一步一步将所有的段子爬取下来吧。</h2><h1 id="第一步：获取数据"><a href="#第一步：获取数据" class="headerlink" title="第一步：获取数据"></a>第一步：获取数据</h1><ol>
<li>按照我们之前的用法，我们需要写一个加载页面的方法。</li>
</ol>
<p>这里我们统一定义一个类，将url请求作为一个成员方法处理。</p>
<p>我们创建一个文件，叫duanzi_spider.py</p>
<p>然后定义一个Spider类，并且添加一个加载页面的成员方法<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Spider</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">        内涵段子爬虫类</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">loadPage</span><span class="params">(self, page)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">            @brief 定义一个url请求网页的方法</span></span><br><span class="line"><span class="string">            @param page 需要请求的第几页</span></span><br><span class="line"><span class="string">            @returns 返回的页面html</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line"></span><br><span class="line">    url = <span class="string">"http://www.neihan8.com/article/list_5_"</span> + str(page)</span><br><span class="line">+ <span class="string">".html"</span></span><br><span class="line">    <span class="comment">#User-Agent头</span></span><br><span class="line">    user_agent = <span class="string">'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT</span></span><br><span class="line"><span class="string">6.1; Trident/5.0'</span></span><br><span class="line"></span><br><span class="line">    headers = &#123;<span class="string">'User-Agent'</span>: user_agent&#125;</span><br><span class="line">    req = urllib2.Request(url, headers = headers)</span><br><span class="line">    response = urllib2.urlopen(req)</span><br><span class="line">    html = response.read()</span><br><span class="line">    <span class="keyword">print</span> html</span><br><span class="line"></span><br><span class="line">    <span class="comment">#return html</span></span><br></pre></td></tr></table></figure></p>
<p><strong>以上的loadPage的实现体想必大家应该很熟悉了，需要注意定义python类的成员方法需要额外添加一个参数self.</strong></p>
<ul>
<li><p>那么loadPage(self, page) 中的page是我们指定去请求第几页。</p>
</li>
<li><p>最后通过 print html打印到屏幕上。</p>
</li>
<li><p>然后我们写一个main函数见到测试一个loadPage方法</p>
</li>
</ul>
<p><strong>2. 写main函数测试一个loadPage方法</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">        ======================</span></span><br><span class="line"><span class="string">            内涵段子小爬虫</span></span><br><span class="line"><span class="string">        ======================</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">print</span> <span class="string">'请按下回车开始'</span></span><br><span class="line">    raw_input()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#定义一个Spider对象</span></span><br><span class="line">    mySpider = Spider()</span><br><span class="line">    mySpider.loadpage(<span class="number">1</span>)</span><br></pre></td></tr></table></figure></p>
<ul>
<li>程序正常执行的话，我们会在屏幕上打印了内涵段子第一页的全部html代码。 但是我们发现，html中的中文部分显示的可能是乱码 。</li>
</ul>
<img src="/2018/05/08/2018050822/1.jpg">
<h3 id="那么我们需要简单的将得到的网页源代码处理一下："><a href="#那么我们需要简单的将得到的网页源代码处理一下：" class="headerlink" title="那么我们需要简单的将得到的网页源代码处理一下："></a>那么我们需要简单的将得到的网页源代码处理一下：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadPage</span><span class="params">(self, page)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">        @brief 定义一个url请求网页的方法</span></span><br><span class="line"><span class="string">        @param page 需要请求的第几页</span></span><br><span class="line"><span class="string">        @returns 返回的页面html</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    url = <span class="string">"http://www.neihan8.com/article/list_5_"</span> + str(page)</span><br><span class="line">+ <span class="string">".html"</span></span><br><span class="line">    <span class="comment">#User-Agent头</span></span><br><span class="line">    user_agent = <span class="string">'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT</span></span><br><span class="line"><span class="string">6.1; Trident/5.0'</span></span><br><span class="line">    headers = &#123;<span class="string">'User-Agent'</span>: user_agent&#125;</span><br><span class="line">    req = urllib2.Request(url, headers = headers)</span><br><span class="line">    response = urllib2.urlopen(req)</span><br><span class="line">    html = response.read()</span><br><span class="line">    gbk_html = html.decode(<span class="string">'gbk'</span>).encode(<span class="string">'utf-8'</span>)</span><br><span class="line">    <span class="comment"># print gbk_html</span></span><br><span class="line">    <span class="keyword">return</span> gbk_html</span><br></pre></td></tr></table></figure>
<pre><code>注意 ：对于每个网站对中文的编码各自不同，所以html.decode(‘gbk’)的写法并不是通用写法，根据网站的编码而异
</code></pre><ul>
<li>这样我们再次执行以下duanzi_spider.py ，会发现之前的中文乱码可以正常显示了。<img src="/2018/05/08/2018050822/2.jpg">
<h1 id="第二步：筛选数据"><a href="#第二步：筛选数据" class="headerlink" title="第二步：筛选数据"></a>第二步：筛选数据</h1></li>
</ul>
<pre><code>接下来我们已经得到了整个页面的数据。 但是，很多内容我们并不关心，所以下一步我们需要进行筛选。 如何筛选，就用到了上一节讲述的正则表达式。
</code></pre><ul>
<li>首先<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br></pre></td></tr></table></figure>
</li>
</ul>
<ul>
<li><p>然后, 在我们得到的gbk_html中进行筛选匹配。<br><strong>我们需要一个匹配规则:</strong></p>
<p>  我们可以打开内涵段子的网页，鼠标点击右键 “ 查看源代码 ” 你会惊奇的发现，我们需要的每个段子的内容都是在一个 &lt;div>标签中，而且每个div都有一个属性class = “f18 mb20”</p>
<img src="/2018/05/08/2018050822/3.jpg">
</li>
</ul>
<pre><code>所以，我们只需要匹配到网页中所有&lt;div class=&quot;f18 mb20&quot;&gt; 到 &lt;/div&gt; 的数据就可以了。
</code></pre><p>根据正则表达式，我们可以推算出一个公式是:</p>
<p>&lt;div.<em>?class=”f18 mb20”&gt;(.</em>?)&lt;/div></p>
<ul>
<li><p>这个表达式实际上就是匹配到所有div中class=”f18 mb20 里面的内容(具体可以看前面正则介绍)</p>
</li>
<li><p>然后将这个正则应用到代码中，我们会得到以下代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadPage</span><span class="params">(self, page)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">        @brief 定义一个url请求网页的方法</span></span><br><span class="line"><span class="string">        @param page 需要请求的第几页</span></span><br><span class="line"><span class="string">        @returns 返回的页面html</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    url = <span class="string">"http://www.neihan8.com/article/list_5_"</span> + str(page)</span><br><span class="line">+ <span class="string">".html"</span></span><br><span class="line">    <span class="comment">#User-Agent头</span></span><br><span class="line">    user_agent = <span class="string">'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT</span></span><br><span class="line"><span class="string">6.1; Trident/5.0'</span></span><br><span class="line">    headers = &#123;<span class="string">'User-Agent'</span>: user_agent&#125;</span><br><span class="line">    req = urllib2.Request(url, headers = headers)</span><br><span class="line">    response = urllib2.urlopen(req)</span><br><span class="line">    html = response.read()</span><br><span class="line">    gbk_html = html.decode(<span class="string">'gbk'</span>).encode(<span class="string">'utf-8'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#找到所有的段子内容&lt;div class = "f18 mb20"&gt;&lt;/div&gt;</span></span><br><span class="line">    <span class="comment">#re.S 如果没有re.S 则是只匹配一行有没有符合规则的字符串，如果没有则下一行重新匹配</span></span><br><span class="line">    <span class="comment"># 如果加上re.S 则是将所有的字符串将一个整体进行匹配</span></span><br><span class="line">    pattern = re.compile(<span class="string">r'&lt;div.*?class="f18 mb20"&gt;(.*?)&lt;/di</span></span><br><span class="line"><span class="string">v&gt;'</span>, re.S)</span><br><span class="line">    item_list = pattern.findall(gbk_html)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> item_list</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printOnePage</span><span class="params">(self, item_list, page)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">        @brief 处理得到的段子列表</span></span><br><span class="line"><span class="string">        @param item_list 得到的段子列表</span></span><br><span class="line"><span class="string">        @param page 处理第几页</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">print</span> <span class="string">"******* 第 %d 页 爬取完毕...*******"</span> %page</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> item_list:</span><br><span class="line">        <span class="keyword">print</span> <span class="string">"================"</span></span><br><span class="line">        <span class="keyword">print</span> ite</span><br></pre></td></tr></table></figure>
</li>
</ul>
<ul>
<li><p>这里需要注意一个是re.S是正则表达式中匹配的一个参数。</p>
</li>
<li><p>如果 没有re.S 则是 只匹配一行 有没有符合规则的字符串，如果没有则下一行重新匹配。</p>
</li>
<li>如果 加上re.S 则是将 所有的字符串 将一个整体进行匹配，findall 将所有匹配到的结果封装到一个list中。</li>
</ul>
<p>然后我们写了一个遍历item_list的一个方法 printOnePage() 。 ok程序写到这，我们再一次执行一下。</p>
<p>Power@PowerMac ~$ python duanzi_spider.py</p>
<p><strong>我们第一页的全部段子，不包含其他信息全部的打印了出来。</strong></p>
<ul>
<li><p>你会发现段子中有很多 &lt;p> , &lt;/p> 很是不舒服，实际上这个是html的一种段落的标签。</p>
</li>
<li><p>在浏览器上看不出来，但是如果按照文本打印会有&lt;p>出现，那么我们只需要把我们不希望的内容去掉即可了。</p>
</li>
<li><p>我们可以如下简单修改一下 printOnePage().</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printOnePage</span><span class="params">(self, item_list, page)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">        @brief 处理得到的段子列表</span></span><br><span class="line"><span class="string">        @param item_list 得到的段子列表</span></span><br><span class="line"><span class="string">        @param page 处理第几页</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">print</span> <span class="string">"******* 第 %d 页 爬取完毕...*******"</span> %page</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> item_list:</span><br><span class="line">        <span class="keyword">print</span> <span class="string">"================"</span></span><br><span class="line">        item = item.replace(<span class="string">"&lt;p&gt;"</span>, <span class="string">""</span>).replace(<span class="string">"&lt;/p&gt;"</span>, <span class="string">""</span>).repl</span><br><span class="line">ace(<span class="string">"&lt;br /&gt;"</span>, <span class="string">""</span>)</span><br><span class="line">        <span class="keyword">print</span> item</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="第三步：保存数据"><a href="#第三步：保存数据" class="headerlink" title="第三步：保存数据"></a>第三步：保存数据</h1><ul>
<li><p>我们可以将所有的段子存放在文件中。比如，我们可以将得到的每个item不是打印出来，而是存放在一个叫 duanzi.txt 的文件中也可以。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">writeToFile</span><span class="params">(self, text)</span>:</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">    @brief 将数据追加写进文件中</span></span><br><span class="line"><span class="string">    @param text 文件内容</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">    myFile = open(<span class="string">"./duanzi.txt"</span>, <span class="string">'a'</span>) <span class="comment">#追加形式打开文件</span></span><br><span class="line">    myFile.write(text)</span><br><span class="line">    myFile.write(<span class="string">"---------------------------------------------</span></span><br><span class="line"><span class="string">--------"</span>)</span><br><span class="line">    myFile.close()</span><br></pre></td></tr></table></figure>
</li>
<li><p>然后我们将print的语句 改成writeToFile() ，当前页面的所有段子就存在了本地的MyStory.txt文件中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printOnePage</span><span class="params">(self, item_list, page)</span>:</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">    @brief 处理得到的段子列表</span></span><br><span class="line"><span class="string">    @param item_list 得到的段子列表</span></span><br><span class="line"><span class="string">    @param page 处理第几页</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">    <span class="keyword">print</span> <span class="string">"******* 第 %d 页 爬取完毕...*******"</span> %page</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> item_list:</span><br><span class="line">        <span class="comment"># print "================"</span></span><br><span class="line">        item = item.replace(<span class="string">"&lt;p&gt;"</span>, <span class="string">""</span>).replace(<span class="string">"&lt;/p&gt;"</span>, <span class="string">""</span>).repl</span><br><span class="line">ace(<span class="string">"&lt;br /&gt;"</span>, <span class="string">""</span>)</span><br><span class="line">        <span class="comment"># print item</span></span><br><span class="line">        self.writeToFile(item)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="第四步：显示数据"><a href="#第四步：显示数据" class="headerlink" title="第四步：显示数据"></a>第四步：显示数据</h1><ul>
<li><p>接下来我们就通过参数的传递对page进行叠加来遍历 内涵段子吧的全部段子内容。</p>
</li>
<li><p>只需要在外层加一些逻辑处理即可。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">doWork</span><span class="params">(self)</span>:</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">    让爬虫开始工作</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">    <span class="keyword">while</span> self.enable:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            item_list = self.loadPage(self.page)</span><br><span class="line">        <span class="keyword">except</span> urllib2.URLError, e:</span><br><span class="line">            <span class="keyword">print</span> e.reason</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#对得到的段子item_list处理</span></span><br><span class="line">        self.printOnePage(item_list, self.page)</span><br><span class="line">        self.page += <span class="number">1</span> <span class="comment">#此页处理完毕，处理下一页</span></span><br><span class="line">        <span class="keyword">print</span> <span class="string">"按回车继续..."</span></span><br><span class="line">        <span class="keyword">print</span> <span class="string">"输入 quit 退出"</span></span><br><span class="line">        command = raw_input()</span><br><span class="line">        <span class="keyword">if</span> (command == <span class="string">"quit"</span>):</span><br><span class="line">            self.enable = <span class="keyword">False</span></span><br><span class="line">            <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<ul>
<li>最后，我们执行我们的代码，完成后查看当前路径下的duanzi.txt文件，里面已经有了我们要的内涵段子。<br><strong>以上便是一个非常精简使用的小爬虫程序，使用起来很是方便，如果想要爬取其他网站的信息，只需要修改其中某些参数和一些细节就行了。</strong></li>
</ul>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/07/2018050720/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mr.Q">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Dynamic-Soul">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/07/2018050720/" itemprop="url">正则表达式Re模块</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-07T20:16:43+08:00">2018-05-07</time>
            

            
            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/爬虫/" itemprop="url" rel="index"><span itemprop="name">爬虫</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="页面解析和数据提取"><a href="#页面解析和数据提取" class="headerlink" title="页面解析和数据提取"></a>页面解析和数据提取</h1><p>一般来讲对我们而言，需要抓取的是某个网站或者某个应用的内容，提取有用的价值。内容一般分为两部分，非结构化的数据 和 结构化的数据。</p>
<pre><code>非结构化数据：先有数据，再有结构，
结构化数据：先有结构、再有数据
不同类型的数据，我们需要采用不同的方式来处理。
</code></pre><hr>
<h2 id="非结构化的数据处理"><a href="#非结构化的数据处理" class="headerlink" title="非结构化的数据处理"></a>非结构化的数据处理</h2><p><strong>文本、电话号码、邮箱地址</strong></p>
<ul>
<li><p>正则表达式<br><strong>HTML 文件</strong></p>
</li>
<li><p>正则表达式</p>
</li>
<li>XPath</li>
<li><p>CSS选择器</p>
<h2 id="结构化的数据处理"><a href="#结构化的数据处理" class="headerlink" title="结构化的数据处理"></a>结构化的数据处理</h2><p><strong>JSON 文件</strong></p>
</li>
<li><p>JSON Path</p>
</li>
<li><p>转化成Python类型进行操作（json类）<br><strong>XML 文件</strong></p>
</li>
<li><p>转化成Python类型（xmltodict）</p>
</li>
<li>XPath</li>
<li>CSS选择器</li>
<li>正则表达式<h1 id="什么是正则表达式"><a href="#什么是正则表达式" class="headerlink" title="什么是正则表达式"></a>什么是正则表达式</h1></li>
</ul>
<pre><code>正则表达式，又称规则表达式，通常被用来检索、替换那些符合某个模式(规则)的文本。

正则表达式是对字符串操作的一种逻辑公式，就是用事先定义好的一些特定字符、及这些特定字符的组合，组成一个“规则字符串”，这个“规则字符串”用来表达对字符串的一种过滤逻辑。
</code></pre><p>给定一个正则表达式和另一个字符串，我们可以达到如下的目的：</p>
<pre><code>给定的字符串是否符合正则表达式的过滤逻辑（“匹配”）；
通过正则表达式，从文本字符串中获取我们想要的特定部分（“过滤”）。
</code></pre><img src="/2018/05/07/2018050720/1.jpg">
<h1 id="正则表达式匹配规则"><a href="#正则表达式匹配规则" class="headerlink" title="正则表达式匹配规则"></a>正则表达式匹配规则</h1><img src="/2018/05/07/2018050720/2.jpg">
<h1 id="Python-的-re-模块"><a href="#Python-的-re-模块" class="headerlink" title="Python 的 re 模块"></a>Python 的 re 模块</h1><p>在 Python 中，我们可以使用内置的 re 模块来使用正则表达式。</p>
<p>有一点需要特别注意的是，正则表达式使用 对特殊字符进行转义，所以如果我们要使用原始字符串，只需加一个 r 前缀，示例：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">r'chuanzhiboke\t\.\tpython'</span></span><br></pre></td></tr></table></figure></p>
<h2 id="re-模块的一般使用步骤如下："><a href="#re-模块的一般使用步骤如下：" class="headerlink" title="re 模块的一般使用步骤如下："></a>re 模块的一般使用步骤如下：</h2><pre><code>1.使用 compile() 函数将正则表达式的字符串形式编译为一个 Pattern 对象

2.通过 Pattern 对象提供的一系列方法对文本进行匹配查找，获得匹配结果，一个 Match 对象。
3.最后使用 Match 对象提供的属性和方法获得信息，根据需要进行其他的操作
</code></pre><h2 id="compile-函数"><a href="#compile-函数" class="headerlink" title="compile 函数"></a>compile 函数</h2><p>compile 函数用于编译正则表达式，生成一个 Pattern 对象，它的一般使用形式如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将正则表达式编译成 Pattern 对象</span></span><br><span class="line">pattern = re.compile(<span class="string">r'\d+'</span>)</span><br></pre></td></tr></table></figure></p>
<p>在上面，我们已将一个正则表达式编译成 Pattern 对象，接下来，我们就可以利用 pattern 的一系列方法对文本进行匹配查找了。</p>
<p>Pattern 对象的一些常用方法主要有：</p>
<ul>
<li>match 方法：从起始位置开始查找，一次匹配</li>
<li>search 方法：从任何位置开始查找，一次匹配</li>
<li>findall 方法：全部匹配，返回列表</li>
<li>finditer 方法：全部匹配，返回迭代器</li>
<li>split 方法：分割字符串，返回列表</li>
<li>sub 方法：替换</li>
</ul>
<h2 id="match-方法"><a href="#match-方法" class="headerlink" title="match 方法"></a>match 方法</h2><p>match 方法用于查找字符串的头部（也可以指定起始位置），它是一次匹配，只要找到了一个匹配的结果就返回，而不是查找所有匹配的结果。它的一般使用形式如下：</p>
<p>match(string[, pos[, endpos]])</p>
<p>其中，string 是待匹配的字符串，pos 和 endpos 是可选参数，指定字符串的起始和终点位置，默认值分别是 0 和 len (字符串长度)。因此，当你不指定 pos 和 endpos 时，match 方法默认匹配字符串的头部。</p>
<p>当匹配成功时，返回一个 Match 对象，如果没有匹配上，则返回 None。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> re</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>pattern = re.compile(<span class="string">r'\d+'</span>)  <span class="comment"># 用于匹配至少一个数字</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = pattern.match(<span class="string">'one12twothree34four'</span>)  <span class="comment"># 查找头部，没有匹配</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">print</span> m</span><br><span class="line"><span class="keyword">None</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = pattern.match(<span class="string">'one12twothree34four'</span>, <span class="number">2</span>, <span class="number">10</span>) <span class="comment"># 从'e'的位置开始匹配，没有匹配</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">print</span> m</span><br><span class="line"><span class="keyword">None</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = pattern.match(<span class="string">'one12twothree34four'</span>, <span class="number">3</span>, <span class="number">10</span>) <span class="comment"># 从'1'的位置开始匹配，正好匹配</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">print</span> m                                         <span class="comment"># 返回一个 Match 对象</span></span><br><span class="line">&lt;_sre.SRE_Match object at <span class="number">0x10a42aac0</span>&gt;</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.group(<span class="number">0</span>)   <span class="comment"># 可省略 0</span></span><br><span class="line"><span class="string">'12'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.start(<span class="number">0</span>)   <span class="comment"># 可省略 0</span></span><br><span class="line"><span class="number">3</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.end(<span class="number">0</span>)     <span class="comment"># 可省略 0</span></span><br><span class="line"><span class="number">5</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.span(<span class="number">0</span>)    <span class="comment"># 可省略 0</span></span><br><span class="line">(<span class="number">3</span>, <span class="number">5</span>)</span><br></pre></td></tr></table></figure></p>
<p>在上面，当匹配成功时返回一个 Match 对象，其中：</p>
<ul>
<li><p>group([group1, …]) 方法用于获得一个或多个分组匹配的字符串，当要获得整个匹配的子串时，可直接使用 group() 或 group(0)；</p>
</li>
<li><p>start([group]) 方法用于获取分组匹配的子串在整个字符串中的起始位置（子串第一个字符的索引），参数默认值为 0；</p>
</li>
<li>end([group]) 方法用于获取分组匹配的子串在整个字符串中的结束位置（子串最后一个字符的索引+1），参数默认值为 0；</li>
<li>span([group]) 方法返回 (start(group), end(group))。</li>
</ul>
<p>再看看一个例子：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> re</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>pattern = re.compile(<span class="string">r'([a-z]+) ([a-z]+)'</span>, re.I)  <span class="comment"># re.I 表示忽略大小写</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = pattern.match(<span class="string">'Hello World Wide Web'</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">print</span> m     <span class="comment"># 匹配成功，返回一个 Match 对象</span></span><br><span class="line">&lt;_sre.SRE_Match object at <span class="number">0x10bea83e8</span>&gt;</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.group(<span class="number">0</span>)  <span class="comment"># 返回匹配成功的整个子串</span></span><br><span class="line"><span class="string">'Hello World'</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.span(<span class="number">0</span>)   <span class="comment"># 返回匹配成功的整个子串的索引</span></span><br><span class="line">(<span class="number">0</span>, <span class="number">11</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.group(<span class="number">1</span>)  <span class="comment"># 返回第一个分组匹配成功的子串</span></span><br><span class="line"><span class="string">'Hello'</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.span(<span class="number">1</span>)   <span class="comment"># 返回第一个分组匹配成功的子串的索引</span></span><br><span class="line">(<span class="number">0</span>, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.group(<span class="number">2</span>)  <span class="comment"># 返回第二个分组匹配成功的子串</span></span><br><span class="line"><span class="string">'World'</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.span(<span class="number">2</span>)   <span class="comment"># 返回第二个分组匹配成功的子串</span></span><br><span class="line">(<span class="number">6</span>, <span class="number">11</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.groups()  <span class="comment"># 等价于 (m.group(1), m.group(2), ...)</span></span><br><span class="line">(<span class="string">'Hello'</span>, <span class="string">'World'</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.group(<span class="number">3</span>)   <span class="comment"># 不存在第三个分组</span></span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">"&lt;stdin&gt;"</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">IndexError: no such group</span><br></pre></td></tr></table></figure></p>
<h2 id="search-方法"><a href="#search-方法" class="headerlink" title="search 方法"></a>search 方法</h2><p>search 方法用于查找字符串的任何位置，它也是一次匹配，只要找到了一个匹配的结果就返回，而不是查找所有匹配的结果，它的一般使用形式如下：</p>
<p>search(string[, pos[, endpos]])</p>
<p>其中，string 是待匹配的字符串，pos 和 endpos 是可选参数，指定字符串的起始和终点位置，默认值分别是 0 和 len (字符串长度)。</p>
<p>当匹配成功时，返回一个 Match 对象，如果没有匹配上，则返回 None。</p>
<p>让我们看看例子：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> re</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>pattern = re.compile(<span class="string">'\d+'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = pattern.search(<span class="string">'one12twothree34four'</span>)  <span class="comment"># 这里如果使用 match 方法则不匹配</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m</span><br><span class="line">&lt;_sre.SRE_Match object at <span class="number">0x10cc03ac0</span>&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.group()</span><br><span class="line"><span class="string">'12'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = pattern.search(<span class="string">'one12twothree34four'</span>, <span class="number">10</span>, <span class="number">30</span>)  <span class="comment"># 指定字符串区间</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m</span><br><span class="line">&lt;_sre.SRE_Match object at <span class="number">0x10cc03b28</span>&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.group()</span><br><span class="line"><span class="string">'34'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.span()</span><br><span class="line">(<span class="number">13</span>, <span class="number">15</span>)</span><br></pre></td></tr></table></figure></p>
<p>再来看一个例子：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="comment"># 将正则表达式编译成 Pattern 对象</span></span><br><span class="line">pattern = re.compile(<span class="string">r'\d+'</span>)</span><br><span class="line"><span class="comment"># 使用 search() 查找匹配的子串，不存在匹配的子串时将返回 None</span></span><br><span class="line"><span class="comment"># 这里使用 match() 无法成功匹配</span></span><br><span class="line">m = pattern.search(<span class="string">'hello 123456 789'</span>)</span><br><span class="line"><span class="keyword">if</span> m:</span><br><span class="line">    <span class="comment"># 使用 Match 获得分组信息</span></span><br><span class="line">    <span class="keyword">print</span> <span class="string">'matching string:'</span>,m.group()</span><br><span class="line">    <span class="comment"># 起始位置和结束位置</span></span><br><span class="line">    <span class="keyword">print</span> <span class="string">'position:'</span>,m.span()</span><br></pre></td></tr></table></figure></p>
<p>执行结果：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">matching string: <span class="number">123456</span></span><br><span class="line">position: (<span class="number">6</span>, <span class="number">12</span>)</span><br></pre></td></tr></table></figure></p>
<h2 id="findall-方法"><a href="#findall-方法" class="headerlink" title="findall 方法"></a>findall 方法</h2><p>上面的 match 和 search 方法都是一次匹配，只要找到了一个匹配的结果就返回。然而，在大多数时候，我们需要搜索整个字符串，获得所有匹配的结果。</p>
<p>findall 方法的使用形式如下：</p>
<p>findall(string[, pos[, endpos]])</p>
<p>其中，string 是待匹配的字符串，pos 和 endpos 是可选参数，指定字符串的起始和终点位置，默认值分别是 0 和 len (字符串长度)。</p>
<p>findall 以列表形式返回全部能匹配的子串，如果没有匹配，则返回一个空列表。</p>
<p>看看例子：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">pattern = re.compile(<span class="string">r'\d+'</span>)   <span class="comment"># 查找数字</span></span><br><span class="line"></span><br><span class="line">result1 = pattern.findall(<span class="string">'hello 123456 789'</span>)</span><br><span class="line">result2 = pattern.findall(<span class="string">'one1two2three3four4'</span>, <span class="number">0</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> result1</span><br><span class="line"><span class="keyword">print</span> result2</span><br></pre></td></tr></table></figure></p>
<p>执行结果：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">'123456'</span>, <span class="string">'789'</span>]</span><br><span class="line">[<span class="string">'1'</span>, <span class="string">'2'</span>]</span><br></pre></td></tr></table></figure></p>
<p>再先看一个栗子：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># re_test.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="comment">#re模块提供一个方法叫compile模块，提供我们输入一个匹配的规则</span></span><br><span class="line"><span class="comment">#然后返回一个pattern实例，我们根据这个规则去匹配字符串</span></span><br><span class="line">pattern = re.compile(<span class="string">r'\d+\.\d*'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#通过partten.findall()方法就能够全部匹配到我们得到的字符串</span></span><br><span class="line">result = pattern.findall(<span class="string">"123.141593, 'bigcat', 232312, 3.15"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#findall 以 列表形式 返回全部能匹配的子串给result</span></span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> result:</span><br><span class="line">    <span class="keyword">print</span> item</span><br></pre></td></tr></table></figure></p>
<p>运行结果：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">123.141593</span></span><br><span class="line"><span class="number">3.15</span></span><br></pre></td></tr></table></figure></p>
<h2 id="finditer-方法"><a href="#finditer-方法" class="headerlink" title="finditer 方法"></a>finditer 方法</h2><p>finditer 方法的行为跟 findall 的行为类似，也是搜索整个字符串，获得所有匹配的结果。但它返回一个顺序访问每一个匹配结果（Match 对象）的迭代器。</p>
<p>看看例子：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line">pattern = re.compile(<span class="string">r'\d+'</span>)</span><br><span class="line"></span><br><span class="line">result_iter1 = pattern.finditer(<span class="string">'hello 123456 789'</span>)</span><br><span class="line">result_iter2 = pattern.finditer(<span class="string">'one1two2three3four4'</span>, <span class="number">0</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> type(result_iter1)</span><br><span class="line"><span class="keyword">print</span> type(result_iter2)</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> <span class="string">'result1...'</span></span><br><span class="line"><span class="keyword">for</span> m1 <span class="keyword">in</span> result_iter1:   <span class="comment"># m1 是 Match 对象</span></span><br><span class="line">    <span class="keyword">print</span> <span class="string">'matching string: &#123;&#125;, position: &#123;&#125;'</span>.format(m1.group(), m1.span())</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> <span class="string">'result2...'</span></span><br><span class="line"><span class="keyword">for</span> m2 <span class="keyword">in</span> result_iter2:</span><br><span class="line">    <span class="keyword">print</span> <span class="string">'matching string: &#123;&#125;, position: &#123;&#125;'</span>.format(m2.group(), m2.span())</span><br></pre></td></tr></table></figure></p>
<p>执行结果：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;type <span class="string">'callable-iterator'</span>&gt;</span><br><span class="line">&lt;type <span class="string">'callable-iterator'</span>&gt;</span><br><span class="line">result1...</span><br><span class="line">matching string: <span class="number">123456</span>, position: (<span class="number">6</span>, <span class="number">12</span>)</span><br><span class="line">matching string: <span class="number">789</span>, position: (<span class="number">13</span>, <span class="number">16</span>)</span><br><span class="line">result2...</span><br><span class="line">matching string: <span class="number">1</span>, position: (<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">matching string: <span class="number">2</span>, position: (<span class="number">7</span>, <span class="number">8</span>)</span><br></pre></td></tr></table></figure></p>
<h2 id="split-方法"><a href="#split-方法" class="headerlink" title="split 方法"></a>split 方法</h2><p>split 方法按照能够匹配的子串将字符串分割后返回列表，它的使用形式如下：</p>
<p>split(string[, maxsplit])</p>
<p>其中，maxsplit 用于指定最大分割次数，不指定将全部分割。</p>
<p>看看例子：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">p = re.compile(<span class="string">r'[\s\,\;]+'</span>)</span><br><span class="line"><span class="keyword">print</span> p.split(<span class="string">'a,b;; c   d'</span>)</span><br></pre></td></tr></table></figure></p>
<p>执行结果：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>, <span class="string">'d'</span>]</span><br></pre></td></tr></table></figure></p>
<h2 id="sub-方法"><a href="#sub-方法" class="headerlink" title="sub 方法"></a>sub 方法</h2><p>sub 方法用于替换。它的使用形式如下：</p>
<p>sub(repl, string[, count])</p>
<p>其中，repl 可以是字符串也可以是一个函数：</p>
<ul>
<li><p>如果 repl 是字符串，则会使用 repl 去替换字符串每一个匹配的子串，并返回替换后的字符串，另外，repl 还可以使用 id 的形式来引用分组，但不能使用编号 0；</p>
</li>
<li><p>如果 repl 是函数，这个方法应当只接受一个参数（Match 对象），并返回一个字符串用于替换（返回的字符串中不能再引用分组）。</p>
</li>
<li>count 用于指定最多替换次数，不指定时全部替换。</li>
</ul>
<p>看看例子：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">p = re.compile(<span class="string">r'(\w+) (\w+)'</span>) <span class="comment"># \w = [A-Za-z0-9]</span></span><br><span class="line">s = <span class="string">'hello 123, hello 456'</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> p.sub(<span class="string">r'hello world'</span>, s)  <span class="comment"># 使用 'hello world' 替换 'hello 123' 和 'hello 456'</span></span><br><span class="line"><span class="keyword">print</span> p.sub(<span class="string">r'\2 \1'</span>, s)        <span class="comment"># 引用分组</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">func</span><span class="params">(m)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">'hi'</span> + <span class="string">' '</span> + m.group(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> p.sub(func, s)</span><br><span class="line"><span class="keyword">print</span> p.sub(func, s, <span class="number">1</span>)         <span class="comment"># 最多替换一次</span></span><br></pre></td></tr></table></figure></p>
<p>执行结果：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hello world, hello world</span><br><span class="line"><span class="number">123</span> hello, <span class="number">456</span> hello</span><br><span class="line">hi <span class="number">123</span>, hi <span class="number">456</span></span><br><span class="line">hi <span class="number">123</span>, hello <span class="number">456</span></span><br></pre></td></tr></table></figure></p>
<h2 id="匹配中文"><a href="#匹配中文" class="headerlink" title="匹配中文"></a>匹配中文</h2><p>在某些情况下，我们想匹配文本中的汉字，有一点需要注意的是，中文的 unicode 编码范围 主要在 [u4e00-u9fa5]，这里说主要是因为这个范围并不完整，比如没有包括全角（中文）标点，不过，在大部分情况下，应该是够用的。</p>
<p>假设现在想把字符串 title = u’你好，hello，世界’ 中的中文提取出来，可以这么做：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">title = <span class="string">u'你好，hello，世界'</span></span><br><span class="line">pattern = re.compile(<span class="string">ur'[\u4e00-\u9fa5]+'</span>)</span><br><span class="line">result = pattern.findall(title)</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> result</span><br></pre></td></tr></table></figure></p>
<p>执行结果:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">u'\u4f60\u597d'</span>, <span class="string">u'\u4e16\u754c'</span>]</span><br></pre></td></tr></table></figure></p>
<h2 id="注意：贪婪模式与非贪婪模式"><a href="#注意：贪婪模式与非贪婪模式" class="headerlink" title="注意：贪婪模式与非贪婪模式"></a>注意：贪婪模式与非贪婪模式</h2><p>1.贪婪模式：在整个表达式匹配成功的前提下，尽可能多的匹配 ( * )；<br>2.非贪婪模式：在整个表达式匹配成功的前提下，尽可能少的匹配 ( ? )；<br><strong>3.Python里数量词默认是贪婪的。</strong></p>
<h3 id="示例一-：-源字符串：abbbc"><a href="#示例一-：-源字符串：abbbc" class="headerlink" title="示例一 ： 源字符串：abbbc"></a>示例一 ： 源字符串：abbbc</h3><ul>
<li><p>使用贪婪的数量词的正则表达式 ab* ，匹配结果： abbb。</p>
<ul>
<li>决定了尽可能多匹配 b，所以a后面所有的 b 都出现了。</li>
</ul>
</li>
<li><p>使用非贪婪的数量词的正则表达式ab*?，匹配结果： a。</p>
<p>   即使前面有 *，但是 ? 决定了尽可能少匹配 b，所以没有 b。</p>
</li>
</ul>
<h3 id="示例二-：-源字符串：aa-lt-div-test1-lt-div-bb-lt-div-test2-lt-div-cc"><a href="#示例二-：-源字符串：aa-lt-div-test1-lt-div-bb-lt-div-test2-lt-div-cc" class="headerlink" title="示例二 ： 源字符串：aa&lt;div>test1&lt;/div>bb&lt;div>test2&lt;/div>cc"></a>示例二 ： 源字符串：aa&lt;div>test1&lt;/div>bb&lt;div>test2&lt;/div>cc</h3><ul>
<li><p>使用贪婪的数量词的正则表达式：&lt;div>.*&lt;/div></p>
</li>
<li><p>匹配结果：&lt;div>test1&lt;/div>bb&lt;div>test2&lt;/div></p>
<p>这里采用的是贪婪模式。在匹配到第一个“&lt;/div>”时已经可以使整个表达式匹配成功，但是由于采用的是贪婪模式，所以仍然要向右尝试匹配，查看是否还有更长的可以成功匹配的子串。匹配到第二个“&lt;/div>”后，向右再没有可以成功匹配的子串，匹配结束，匹配结果为“&lt;div>test1&lt;/div>bb&lt;div>test2&lt;/div>”</p>
</li>
<li><p>使用非贪婪的数量词的正则表达式：&lt;div>.*?&lt;/div></p>
</li>
<li><p>匹配结果：&lt;div>test1&lt;/div></p>
<p>正则表达式二采用的是非贪婪模式，在匹配到第一个“&lt;/div>”时使整个表达式匹配成功，由于采用的是非贪婪模式，所以结束匹配，不再向右尝试，匹配结果为“&lt;div>test1&lt;/div>”。</p>
</li>
</ul>
<p><a href="http://tool.oschina.net/regex/" target="_blank" rel="noopener">正则表达式测试网址</a></p>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/06/2018050622/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mr.Q">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Dynamic-Soul">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/06/2018050622/" itemprop="url">Request模块</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-06T22:24:45+08:00">2018-05-06</time>
            

            
            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/爬虫/" itemprop="url" rel="index"><span itemprop="name">爬虫</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Requests-让-HTTP-服务人类"><a href="#Requests-让-HTTP-服务人类" class="headerlink" title="Requests: 让 HTTP 服务人类"></a>Requests: 让 HTTP 服务人类</h1><p>虽然Python的标准库中 urllib2 模块已经包含了平常我们使用的大多数功能，但是它的 API 使用起来让人感觉不太好，而 Requests 自称 “HTTP for Humans”，说明使用更简洁方便。</p>
<pre><code>Requests 唯一的一个非转基因的 Python HTTP 库，人类可以安全享用：）
</code></pre><h2 id="Requests-继承了urllib2的所有特性。Requests支持HTTP连接保持和连接池，支持使用cookie保持会话，支持文件上传，支持自动确定响应内容的编码，支持国际化的-URL-和-POST-数据自动编码。"><a href="#Requests-继承了urllib2的所有特性。Requests支持HTTP连接保持和连接池，支持使用cookie保持会话，支持文件上传，支持自动确定响应内容的编码，支持国际化的-URL-和-POST-数据自动编码。" class="headerlink" title="Requests 继承了urllib2的所有特性。Requests支持HTTP连接保持和连接池，支持使用cookie保持会话，支持文件上传，支持自动确定响应内容的编码，支持国际化的 URL 和 POST 数据自动编码。"></a>Requests 继承了urllib2的所有特性。Requests支持HTTP连接保持和连接池，支持使用cookie保持会话，支持文件上传，支持自动确定响应内容的编码，支持国际化的 URL 和 POST 数据自动编码。</h2><h3 id="requests-的底层实现其实就是-urllib3"><a href="#requests-的底层实现其实就是-urllib3" class="headerlink" title="requests 的底层实现其实就是 urllib3"></a>requests 的底层实现其实就是 urllib3</h3><p>Requests的文档非常完备，中文文档也相当不错。Requests能完全满足当前网络的需求，支持Python 2.6—3.5，而且能在PyPy下完美运行。</p>
<p>开源地址：<a href="https://github.com/kennethreitz/requests" target="_blank" rel="noopener">https://github.com/kennethreitz/requests</a></p>
<p>中文文档 API： <a href="http://docs.python-requests.org/zh_CN/latest/index.html" target="_blank" rel="noopener">http://docs.python-requests.org/zh_CN/latest/index.html</a></p>
<h2 id="安装方式"><a href="#安装方式" class="headerlink" title="安装方式"></a>安装方式</h2><p>利用 pip 安装 或者利用 easy_install 都可以完成安装：</p>
<p>$ pip install requests</p>
<p>$ easy_install requests</p>
<h2 id="基本GET请求（headers参数-和-parmas参数）"><a href="#基本GET请求（headers参数-和-parmas参数）" class="headerlink" title="基本GET请求（headers参数 和 parmas参数）"></a>基本GET请求（headers参数 和 parmas参数）</h2><p><strong>1.最基本的GET请求可以直接用get方法</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">response = requests.get(<span class="string">"http://www.baidu.com/"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 也可以这么写</span></span><br><span class="line"><span class="comment"># response = requests.request("get", "http://www.baidu.com/")</span></span><br></pre></td></tr></table></figure></p>
<p><strong>2.添加 headers 和 查询参数</strong><br>如果想添加 headers，可以传入headers参数来增加请求头中的headers信息。如果要将参数放在url中传递，可以利用 params 参数。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">kw = &#123;<span class="string">'wd'</span>:<span class="string">'长城'</span>&#125;</span><br><span class="line"></span><br><span class="line">headers = &#123;<span class="string">"User-Agent"</span>: <span class="string">"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.99 Safari/537.36"</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># params 接收一个字典或者字符串的查询参数，字典类型自动转换为url编码，不需要urlencode()</span></span><br><span class="line">response = requests.get(<span class="string">"http://www.baidu.com/s?"</span>, params = kw, headers = headers)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看响应内容，response.text 返回的是Unicode格式的数据</span></span><br><span class="line"><span class="keyword">print</span> response.text</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看响应内容，response.content返回的字节流数据</span></span><br><span class="line"><span class="keyword">print</span> respones.content</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看完整url地址</span></span><br><span class="line"><span class="keyword">print</span> response.url</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看响应头部字符编码</span></span><br><span class="line"><span class="keyword">print</span> response.encoding</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看响应码</span></span><br><span class="line"><span class="keyword">print</span> response.status_code</span><br></pre></td></tr></table></figure></p>
<p>运行结果<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">......</span><br><span class="line"></span><br><span class="line">......</span><br><span class="line"></span><br><span class="line"><span class="string">'http://www.baidu.com/s?wd=%E9%95%BF%E5%9F%8E'</span></span><br><span class="line"></span><br><span class="line"><span class="string">'utf-8'</span></span><br><span class="line"></span><br><span class="line"><span class="number">200</span></span><br></pre></td></tr></table></figure></p>
<ul>
<li><p>使用response.text 时，Requests 会基于 HTTP 响应的文本编码自动解码响应内容，大多数 Unicode 字符集都能被无缝地解码。</p>
</li>
<li><p>使用response.content 时，返回的是服务器响应数据的原始二进制字节流，可以用来保存图片等二进制文件。</p>
</li>
</ul>
<h2 id="基本POST请求（data参数）"><a href="#基本POST请求（data参数）" class="headerlink" title="基本POST请求（data参数）"></a>基本POST请求（data参数）</h2><p><strong>1.最基本的GET请求可以直接用post方法</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">response = requests.post(<span class="string">"http://www.baidu.com/"</span>, data = data)</span><br></pre></td></tr></table></figure></p>
<p><strong>2.传入data数据</strong><br>对于 POST 请求来说，我们一般需要为它增加一些参数。那么最基本的传参方法可以利用 data 这个参数。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">formdata = &#123;</span><br><span class="line">    <span class="string">"type"</span>:<span class="string">"AUTO"</span>,</span><br><span class="line">    <span class="string">"i"</span>:<span class="string">"i love python"</span>,</span><br><span class="line">    <span class="string">"doctype"</span>:<span class="string">"json"</span>,</span><br><span class="line">    <span class="string">"xmlVersion"</span>:<span class="string">"1.8"</span>,</span><br><span class="line">    <span class="string">"keyfrom"</span>:<span class="string">"fanyi.web"</span>,</span><br><span class="line">    <span class="string">"ue"</span>:<span class="string">"UTF-8"</span>,</span><br><span class="line">    <span class="string">"action"</span>:<span class="string">"FY_BY_ENTER"</span>,</span><br><span class="line">    <span class="string">"typoResult"</span>:<span class="string">"true"</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">url = <span class="string">"http://fanyi.youdao.com/translate?smartresult=dict&amp;smartresult=rule&amp;smartresult=ugc&amp;sessionFrom=null"</span></span><br><span class="line"></span><br><span class="line">headers=&#123; <span class="string">"User-Agent"</span>: <span class="string">"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36"</span>&#125;</span><br><span class="line"></span><br><span class="line">response = requests.post(url, data = formdata, headers = headers)</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> response.text</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果是json文件可以直接显示</span></span><br><span class="line"><span class="keyword">print</span> response.json()</span><br></pre></td></tr></table></figure></p>
<p>运行结果<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="string">"type"</span>:<span class="string">"EN2ZH_CN"</span>,<span class="string">"errorCode"</span>:<span class="number">0</span>,<span class="string">"elapsedTime"</span>:<span class="number">2</span>,<span class="string">"translateResult"</span>:[[&#123;<span class="string">"src"</span>:<span class="string">"i love python"</span>,<span class="string">"tgt"</span>:<span class="string">"我喜欢python"</span>&#125;]],<span class="string">"smartResult"</span>:&#123;<span class="string">"type"</span>:<span class="number">1</span>,<span class="string">"entries"</span>:[<span class="string">""</span>,<span class="string">"肆文"</span>,<span class="string">"高德纳"</span>]&#125;&#125;</span><br><span class="line"></span><br><span class="line">&#123;<span class="string">u'errorCode'</span>: <span class="number">0</span>, <span class="string">u'elapsedTime'</span>: <span class="number">0</span>, <span class="string">u'translateResult'</span>: [[&#123;<span class="string">u'src'</span>: <span class="string">u'i love python'</span>, <span class="string">u'tgt'</span>: <span class="string">u'\u6211\u559c\u6b22python'</span>&#125;]], <span class="string">u'smartResult'</span>: &#123;<span class="string">u'type'</span>: <span class="number">1</span>, <span class="string">u'entries'</span>: [<span class="string">u''</span>, <span class="string">u'\u8086\u6587'</span>, <span class="string">u'\u9ad8\u5fb7\u7eb3'</span>]&#125;, <span class="string">u'type'</span>: <span class="string">u'EN2ZH_CN'</span>&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="代理（proxies参数）"><a href="#代理（proxies参数）" class="headerlink" title="代理（proxies参数）"></a>代理（proxies参数）</h2><p>如果需要使用代理，你可以通过为任意请求方法提供 proxies 参数来配置单个请求：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据协议类型，选择不同的代理</span></span><br><span class="line">proxies = &#123;</span><br><span class="line">  <span class="string">"http"</span>: <span class="string">"http://12.34.56.79:9527"</span>,</span><br><span class="line">  <span class="string">"https"</span>: <span class="string">"http://12.34.56.79:9527"</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">response = requests.get(<span class="string">"http://www.baidu.com"</span>, proxies = proxies)</span><br><span class="line"><span class="keyword">print</span> response.text</span><br></pre></td></tr></table></figure></p>
<p>也可以通过本地环境变量 HTTP_PROXY 和 HTTPS_PROXY 来配置代理：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export HTTP_PROXY=<span class="string">"http://12.34.56.79:9527"</span></span><br><span class="line">export HTTPS_PROXY=<span class="string">"https://12.34.56.79:9527"</span></span><br></pre></td></tr></table></figure></p>
<h2 id="私密代理验证（特定格式）-和-Web客户端验证（auth-参数）"><a href="#私密代理验证（特定格式）-和-Web客户端验证（auth-参数）" class="headerlink" title="私密代理验证（特定格式） 和 Web客户端验证（auth 参数）"></a>私密代理验证（特定格式） 和 Web客户端验证（auth 参数）</h2><p>urllib2 这里的做法比较复杂，requests只需要一步：</p>
<h3 id="私密代理"><a href="#私密代理" class="headerlink" title="私密代理"></a>私密代理</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果代理需要使用HTTP Basic Auth，可以使用下面这种格式：</span></span><br><span class="line">proxy = &#123; <span class="string">"http"</span>: <span class="string">"mr_mao_hacker:sffqry9r@61.158.163.130:16816"</span> &#125;</span><br><span class="line"></span><br><span class="line">response = requests.get(<span class="string">"http://www.baidu.com"</span>, proxies = proxy)</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> response.text</span><br></pre></td></tr></table></figure>
<h3 id="web客户端验证"><a href="#web客户端验证" class="headerlink" title="web客户端验证"></a>web客户端验证</h3><p>如果是Web客户端验证，需要添加 auth = (账户名, 密码)<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">auth=(<span class="string">'test'</span>, <span class="string">'123456'</span>)</span><br><span class="line"></span><br><span class="line">response = requests.get(<span class="string">'http://192.168.199.107'</span>, auth = auth)</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> response.text</span><br></pre></td></tr></table></figure></p>
<h2 id="Cookies-和-Sission"><a href="#Cookies-和-Sission" class="headerlink" title="Cookies 和 Sission"></a>Cookies 和 Sission</h2><h3 id="Cookies"><a href="#Cookies" class="headerlink" title="Cookies"></a>Cookies</h3><p>如果一个响应中包含了cookie，那么我们可以利用 cookies参数拿到：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">response = requests.get(<span class="string">"http://www.baidu.com/"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 7. 返回CookieJar对象:</span></span><br><span class="line">cookiejar = response.cookies</span><br><span class="line"></span><br><span class="line"><span class="comment"># 8. 将CookieJar转为字典：</span></span><br><span class="line">cookiedict = requests.utils.dict_from_cookiejar(cookiejar)</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> cookiejar</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> cookiedict</span><br></pre></td></tr></table></figure></p>
<p>运行结果：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;RequestsCookieJar[&lt;Cookie BDORZ=<span class="number">27315</span> <span class="keyword">for</span> .baidu.com/&gt;]&gt;</span><br><span class="line"></span><br><span class="line">&#123;<span class="string">'BDORZ'</span>: <span class="string">'27315'</span>&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="Sission"><a href="#Sission" class="headerlink" title="Sission"></a>Sission</h3><p>在 requests 里，session对象是一个非常常用的对象，这个对象代表一次用户会话：从客户端浏览器连接服务器开始，到客户端浏览器与服务器断开。</p>
<p>会话能让我们在跨请求时候保持某些参数，比如在同一个 Session 实例发出的所有请求之间保持 cookie 。</p>
<h3 id="实现人人网登录"><a href="#实现人人网登录" class="headerlink" title="实现人人网登录"></a>实现人人网登录</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 创建session对象，可以保存Cookie值</span></span><br><span class="line">ssion = requests.session()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 处理 headers</span></span><br><span class="line">headers = &#123;<span class="string">"User-Agent"</span>: <span class="string">"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.99 Safari/537.36"</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 需要登录的用户名和密码</span></span><br><span class="line">data = &#123;<span class="string">"email"</span>:<span class="string">"mr_mao_hacker@163.com"</span>, <span class="string">"password"</span>:<span class="string">"alarmchime"</span>&#125;  </span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 发送附带用户名和密码的请求，并获取登录后的Cookie值，保存在ssion里</span></span><br><span class="line">ssion.post(<span class="string">"http://www.renren.com/PLogin.do"</span>, data = data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5. ssion包含用户登录后的Cookie值，可以直接访问那些登录后才可以访问的页面</span></span><br><span class="line">response = ssion.get(<span class="string">"http://www.renren.com/410043129/profile"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 6. 打印响应内容</span></span><br><span class="line"><span class="keyword">print</span> response.text</span><br></pre></td></tr></table></figure>
<h2 id="处理HTTPS请求-SSL证书验证"><a href="#处理HTTPS请求-SSL证书验证" class="headerlink" title="处理HTTPS请求 SSL证书验证"></a>处理HTTPS请求 SSL证书验证</h2><p>Requests也可以为HTTPS请求验证SSL证书：</p>
<ul>
<li>要想检查某个主机的SSL证书，你可以使用 verify 参数（也可以不写）<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">response = requests.get(<span class="string">"https://www.baidu.com/"</span>, verify=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 也可以省略不写</span></span><br><span class="line"><span class="comment"># response = requests.get("https://www.baidu.com/")</span></span><br><span class="line"><span class="keyword">print</span> r.text</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>运行结果：<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;!--STATUS OK--&gt;&lt;html&gt; &lt;head&gt;&lt;meta http-equiv=content-type content=text/html;charset=utf-8&gt;&lt;meta http-equiv=X-UA-Compatible content=IE=Edge&gt;百度一下，你就知道 ....</span><br></pre></td></tr></table></figure></p>
<ul>
<li>如果SSL证书验证不通过，或者不信任服务器的安全证书，则会报出SSLError，据说 12306 证书是自己做的：<img src="/2018/05/06/2018050622/1.jpg">
来测试一下：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">response = requests.get(<span class="string">"https://www.12306.cn/mormhweb/"</span>)</span><br><span class="line"><span class="keyword">print</span> response.text</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>果然：</p>
<p>SSLError: (“bad handshake: Error([(‘SSL routines’, ‘ssl3_get_server_certificate’, ‘certificate verify failed’)],)”,)</p>
<p>如果我们想跳过 12306 的证书验证，把 verify 设置为 False 就可以正常请求了。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">r = requests.get(<span class="string">"https://www.12306.cn/mormhweb/"</span>, verify = <span class="keyword">False</span>)</span><br></pre></td></tr></table></figure></p>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/05/2018050522/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mr.Q">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Dynamic-Soul">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/05/05/2018050522/" itemprop="url">urllib2：URLError与HTTPError</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-05T22:39:08+08:00">2018-05-05</time>
            

            
            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/爬虫/" itemprop="url" rel="index"><span itemprop="name">爬虫</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="urllib2-的异常错误处理"><a href="#urllib2-的异常错误处理" class="headerlink" title="urllib2 的异常错误处理"></a>urllib2 的异常错误处理</h1><p>在我们用urlopen或opener.open方法发出一个请求时，如果urlopen或opener.open不能处理这个response，就产生错误。</p>
<p>这里主要说的是URLError和HTTPError，以及对它们的错误处理。</p>
<hr>
<h2 id="URLError"><a href="#URLError" class="headerlink" title="URLError"></a>URLError</h2><p>URLError 产生的原因主要有：</p>
<pre><code>1. 没有网络连接
2. 服务器连接失败
3. 找不到指定的服务器
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># urllib2_urlerror.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line"></span><br><span class="line">requset = urllib2.Request(<span class="string">'http://www.ajkfhafwjqh.com'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    urllib2.urlopen(request, timeout=<span class="number">5</span>)</span><br><span class="line"><span class="keyword">except</span> urllib2.URLError, err:</span><br><span class="line">    <span class="keyword">print</span> err</span><br></pre></td></tr></table></figure>
<p>运行结果如下：</p>
<urlopen error="" [errno="" 8]="" nodename="" nor="" servname="" provided,="" or="" not="" known="">

<pre><code>urlopen error，错误代码8，错误原因是没有找到指定的服务器。
</code></pre><h2 id="HTTPError"><a href="#HTTPError" class="headerlink" title="HTTPError"></a>HTTPError</h2><p>HTTPError是URLError的子类，我们发出一个请求时，服务器上都会对应一个response应答对象，其中它包含一个数字”响应状态码”。</p>
<p>如果urlopen或opener.open不能处理的，会产生一个HTTPError，对应相应的状态码，HTTP状态码表示HTTP协议所返回的响应的状态。</p>
<p><strong>注意，urllib2可以为我们处理重定向的页面（也就是3开头的响应码），100-299范围的号码表示成功，所以我们只能看到400-599的错误号码。</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># urllib2_httperror.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line"></span><br><span class="line">requset = urllib2.Request(<span class="string">'http://blog.baidu.com/itcast'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    urllib2.urlopen(requset)</span><br><span class="line"><span class="keyword">except</span> urllib2.HTTPError, err:</span><br><span class="line">    <span class="keyword">print</span> err.code</span><br><span class="line">    <span class="keyword">print</span> err</span><br></pre></td></tr></table></figure></p>
<p>运行结果如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">404</span></span><br><span class="line">HTTP Error <span class="number">404</span>: Not Found</span><br></pre></td></tr></table></figure></p>
<pre><code>HTTP Error，错误代号是404，错误原因是Not Found，说明服务器无法找到被请求的页面。

通常产生这种错误的，要么url不对，要么ip被封。
</code></pre><h2 id="改进版"><a href="#改进版" class="headerlink" title="改进版"></a>改进版</h2><p>由于HTTPError的父类是URLError，所以父类的异常应当写到子类异常的后面，所以上述的代码可以这么改写：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># urllib2_botherror.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line"></span><br><span class="line">requset = urllib2.Request(<span class="string">'http://blog.baidu.com/itcast'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    urllib2.urlopen(requset)</span><br><span class="line"></span><br><span class="line"><span class="keyword">except</span> urllib2.HTTPError, err:</span><br><span class="line">    <span class="keyword">print</span> err.code</span><br><span class="line"></span><br><span class="line"><span class="keyword">except</span> urllib2.URLError, err:</span><br><span class="line">    <span class="keyword">print</span> err</span><br><span class="line"></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">print</span> <span class="string">"Good Job"</span></span><br></pre></td></tr></table></figure></p>
<p>运行结果如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">404</span></span><br></pre></td></tr></table></figure></p>
<p><strong>这样我们就可以做到，首先捕获子类的异常，如果子类捕获不到，那么可以捕获父类的异常。</strong></p>
<h1 id="HTTP响应状态码参考："><a href="#HTTP响应状态码参考：" class="headerlink" title="HTTP响应状态码参考："></a>HTTP响应状态码参考：</h1><pre><code>1xx:信息

100 Continue
服务器仅接收到部分请求，但是一旦服务器并没有拒绝该请求，客户端应该继续发送其余的请求。
101 Switching Protocols
服务器转换协议：服务器将遵从客户的请求转换到另外一种协议。



2xx:成功

200 OK
请求成功（其后是对GET和POST请求的应答文档）
201 Created
请求被创建完成，同时新的资源被创建。
202 Accepted
供处理的请求已被接受，但是处理未完成。
203 Non-authoritative Information
文档已经正常地返回，但一些应答头可能不正确，因为使用的是文档的拷贝。
204 No Content
没有新文档。浏览器应该继续显示原来的文档。如果用户定期地刷新页面，而Servlet可以确定用户文档足够新，这个状态代码是很有用的。
205 Reset Content
没有新文档。但浏览器应该重置它所显示的内容。用来强制浏览器清除表单输入内容。
206 Partial Content
客户发送了一个带有Range头的GET请求，服务器完成了它。



3xx:重定向

300 Multiple Choices
多重选择。链接列表。用户可以选择某链接到达目的地。最多允许五个地址。
301 Moved Permanently
所请求的页面已经转移至新的url。
302 Moved Temporarily
所请求的页面已经临时转移至新的url。
303 See Other
所请求的页面可在别的url下被找到。
304 Not Modified
未按预期修改文档。客户端有缓冲的文档并发出了一个条件性的请求（一般是提供If-Modified-Since头表示客户只想比指定日期更新的文档）。服务器告诉客户，原来缓冲的文档还可以继续使用。
305 Use Proxy
客户请求的文档应该通过Location头所指明的代理服务器提取。
306 Unused
此代码被用于前一版本。目前已不再使用，但是代码依然被保留。
307 Temporary Redirect
被请求的页面已经临时移至新的url。



4xx:客户端错误

400 Bad Request
服务器未能理解请求。
401 Unauthorized
被请求的页面需要用户名和密码。
401.1
登录失败。
401.2
服务器配置导致登录失败。
401.3
由于 ACL 对资源的限制而未获得授权。
401.4
筛选器授权失败。
401.5
ISAPI/CGI 应用程序授权失败。
401.7
访问被 Web 服务器上的 URL 授权策略拒绝。这个错误代码为 IIS 6.0 所专用。
402 Payment Required
此代码尚无法使用。
403 Forbidden
对被请求页面的访问被禁止。
403.1
执行访问被禁止。
403.2
读访问被禁止。
403.3
写访问被禁止。
403.4
要求 SSL。
403.5
要求 SSL 128。
403.6
IP 地址被拒绝。
403.7
要求客户端证书。
403.8
站点访问被拒绝。
403.9
用户数过多。
403.10
配置无效。
403.11
密码更改。
403.12
拒绝访问映射表。
403.13
客户端证书被吊销。
403.14
拒绝目录列表。
403.15
超出客户端访问许可。
403.16
客户端证书不受信任或无效。
403.17
客户端证书已过期或尚未生效。
403.18
在当前的应用程序池中不能执行所请求的 URL。这个错误代码为 IIS 6.0 所专用。
403.19
不能为这个应用程序池中的客户端执行 CGI。这个错误代码为 IIS 6.0 所专用。
403.20
Passport 登录失败。这个错误代码为 IIS 6.0 所专用。
404 Not Found
服务器无法找到被请求的页面。
404.0
没有找到文件或目录。
404.1
无法在所请求的端口上访问 Web 站点。
404.2
Web 服务扩展锁定策略阻止本请求。
404.3
MIME 映射策略阻止本请求。
405 Method Not Allowed
请求中指定的方法不被允许。
406 Not Acceptable
服务器生成的响应无法被客户端所接受。
407 Proxy Authentication Required
用户必须首先使用代理服务器进行验证，这样请求才会被处理。
408 Request Timeout
请求超出了服务器的等待时间。
409 Conflict
由于冲突，请求无法被完成。
410 Gone
被请求的页面不可用。
411 Length Required
&quot;Content-Length&quot; 未被定义。如果无此内容，服务器不会接受请求。
412 Precondition Failed
请求中的前提条件被服务器评估为失败。
413 Request Entity Too Large
由于所请求的实体的太大，服务器不会接受请求。
414 Request-url Too Long
由于url太长，服务器不会接受请求。当post请求被转换为带有很长的查询信息的get请求时，就会发生这种情况。
415 Unsupported Media Type
由于媒介类型不被支持，服务器不会接受请求。
416 Requested Range Not Satisfiable
服务器不能满足客户在请求中指定的Range头。
417 Expectation Failed
执行失败。
423
锁定的错误。



5xx:服务器错误

500 Internal Server Error
请求未完成。服务器遇到不可预知的情况。
500.12
应用程序正忙于在 Web 服务器上重新启动。
500.13
Web 服务器太忙。
500.15
不允许直接请求 Global.asa。
500.16
UNC 授权凭据不正确。这个错误代码为 IIS 6.0 所专用。
500.18
URL 授权存储不能打开。这个错误代码为 IIS 6.0 所专用。
500.100
内部 ASP 错误。
501 Not Implemented
请求未完成。服务器不支持所请求的功能。
502 Bad Gateway
请求未完成。服务器从上游服务器收到一个无效的响应。
502.1
CGI 应用程序超时。　·
502.2
CGI 应用程序出错。
503 Service Unavailable
请求未完成。服务器临时过载或当机。
504 Gateway Timeout
网关超时。
505 HTTP Version Not Supported
服务器不支持请求中指明的HTTP协议版本
</code></pre></urlopen>
          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/3/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/5/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>



          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.gif"
                alt="Mr.Q" />
            
              <p class="site-author-name" itemprop="name">Mr.Q</p>
              <p class="site-description motion-element" itemprop="description">我希望时间没有流走，世界还停在过去，昏黄的光还照在旧日的路上，我刚刚走过，恰与你们相识。</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">47</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                    <span class="site-state-item-count">1</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">7</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          

          

          
          

          
          

          
            
          
          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Mr.Q</span>

  

  
</div>




  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/theme-next/hexo-theme-next">NexT.Gemini</a> v6.0.6</div>




<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共59.5k字</span>
</div>
        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>














  













  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=6.0.6"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=6.0.6"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=6.0.6"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=6.0.6"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=6.0.6"></script>



  



	





  





  










  





  

  

  

  

  
  

  

  

  

  


  
</body>
</html>
